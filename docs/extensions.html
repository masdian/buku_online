<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Common Extensions | Mixed Models with R</title>
  <meta name="description" content="This is an introduction to using mixed models in R. It covers the most common techniques employed, with demonstration primarily via the lme4 package. Discussion includes extensions into generalized mixed models, Bayesian approaches, and realms beyond." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Common Extensions | Mixed Models with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/mixed-models-with-R/" />
  <meta property="og:image" content="https://m-clark.github.io/mixed-models-with-R/img/nineteeneightyR.png" />
  <meta property="og:description" content="This is an introduction to using mixed models in R. It covers the most common techniques employed, with demonstration primarily via the lme4 package. Discussion includes extensions into generalized mixed models, Bayesian approaches, and realms beyond." />
  <meta name="github-repo" content="m-clark/mixed-models-with-R/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Common Extensions | Mixed Models with R" />
  
  <meta name="twitter:description" content="This is an introduction to using mixed models in R. It covers the most common techniques employed, with demonstration primarily via the lme4 package. Discussion includes extensions into generalized mixed models, Bayesian approaches, and realms beyond." />
  <meta name="twitter:image" content="https://m-clark.github.io/mixed-models-with-R/img/nineteeneightyR.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/R.ico" type="image/x-icon" />
<link rel="prev" href="random_slopes.html"/>
<link rel="next" href="issues.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.17/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/book.css" type="text/css" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='before'><a href="./">Mixed Models with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>date: “2021-03-12”</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#overview"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#goals"><i class="fa fa-check"></i>Goals</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#workshop"><i class="fa fa-check"></i>Workshop</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#key-packages"><i class="fa fa-check"></i>Key packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html"><i class="fa fa-check"></i>Mixed Models</a>
<ul>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#terminology"><i class="fa fa-check"></i>Terminology</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#kinds-of-clustering"><i class="fa fa-check"></i>Kinds of Clustering</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#random-intercepts-model"><i class="fa fa-check"></i>Random Intercepts Model</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#example-student-gpa"><i class="fa fa-check"></i>Example: Student GPA</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#the-standard-regression-model"><i class="fa fa-check"></i>The Standard Regression Model</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#the-mixed-model"><i class="fa fa-check"></i>The Mixed Model</a>
<ul>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#initial-depiction"><i class="fa fa-check"></i>Initial depiction</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#as-a-multi-level-model"><i class="fa fa-check"></i>As a multi-level model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#application"><i class="fa fa-check"></i>Application</a>
<ul>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#initial-visualization"><i class="fa fa-check"></i>Initial visualization</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#standard-regression"><i class="fa fa-check"></i>Standard regression</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#regression-by-cluster"><i class="fa fa-check"></i>Regression by cluster</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#running-a-mixed-model"><i class="fa fa-check"></i>Running a mixed model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#cluster-level-covariates"><i class="fa fa-check"></i>Cluster Level Covariates</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#summary-of-mixed-model-basics"><i class="fa fa-check"></i>Summary of Mixed Model Basics</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#exercises-for-starting-out"><i class="fa fa-check"></i>Exercises for Starting Out</a>
<ul>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#sleep"><i class="fa fa-check"></i>Sleep</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#adding-the-cluster-level-covariate"><i class="fa fa-check"></i>Adding the cluster-level covariate</a></li>
<li class="chapter" data-level="" data-path="random_intercepts.html"><a href="random_intercepts.html#simulating-a-mixed-model"><i class="fa fa-check"></i>Simulating a mixed model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="random_slopes.html"><a href="random_slopes.html"><i class="fa fa-check"></i>More Random Effects</a>
<ul>
<li class="chapter" data-level="" data-path="random_slopes.html"><a href="random_slopes.html#application-1"><i class="fa fa-check"></i>Application</a></li>
<li class="chapter" data-level="" data-path="random_slopes.html"><a href="random_slopes.html#comparison-to-many-regressions"><i class="fa fa-check"></i>Comparison to many regressions</a></li>
<li class="chapter" data-level="" data-path="random_slopes.html"><a href="random_slopes.html#visualization-of-effects"><i class="fa fa-check"></i>Visualization of effects</a></li>
<li class="chapter" data-level="" data-path="random_slopes.html"><a href="random_slopes.html#summary-of-random-slopes"><i class="fa fa-check"></i>Summary of Random Slopes</a></li>
<li class="chapter" data-level="" data-path="random_slopes.html"><a href="random_slopes.html#exercises-for-random-slopes"><i class="fa fa-check"></i>Exercises for Random Slopes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i>Common Extensions</a>
<ul>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#additional-grouping-structure"><i class="fa fa-check"></i>Additional Grouping Structure</a>
<ul>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#cross-classified-models"><i class="fa fa-check"></i>Cross-classified models</a></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#hierarchical-structure"><i class="fa fa-check"></i>Hierarchical structure</a></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#crossed-vs.-nested"><i class="fa fa-check"></i>Crossed vs. nested</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#residual-structure"><i class="fa fa-check"></i>Residual Structure</a>
<ul>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#heterogeneous-variance"><i class="fa fa-check"></i>Heterogeneous variance</a></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#autocorrelation"><i class="fa fa-check"></i>Autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#generalized-linear-mixed-models"><i class="fa fa-check"></i>Generalized Linear Mixed Models</a></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#exercises-for-extensions"><i class="fa fa-check"></i>Exercises for Extensions</a>
<ul>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#sociometric-data"><i class="fa fa-check"></i>Sociometric data</a></li>
<li class="chapter" data-level="" data-path="extensions.html"><a href="extensions.html#patents"><i class="fa fa-check"></i>Patents</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html"><i class="fa fa-check"></i>Issues</a>
<ul>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#variance-accounted-for"><i class="fa fa-check"></i>Variance Accounted For</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#common-alternatives-to-mixed-models"><i class="fa fa-check"></i>Common Alternatives to Mixed Models</a>
<ul>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#growth-curve-models"><i class="fa fa-check"></i>Growth curve models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#sample-sizes"><i class="fa fa-check"></i>Sample Sizes</a>
<ul>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#small-number-of-clusters"><i class="fa fa-check"></i>Small number of clusters</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#small-number-of-observations-within-clusters"><i class="fa fa-check"></i>Small number of observations within clusters</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#balancedmissing-values"><i class="fa fa-check"></i>Balanced/Missing values</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#big-data"><i class="fa fa-check"></i>Big data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#model-comparison"><i class="fa fa-check"></i>Model Comparison</a></li>
<li class="chapter" data-level="" data-path="issues.html"><a href="issues.html#convergence"><i class="fa fa-check"></i>Convergence</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i>Bayesian Approaches</a>
<ul>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html#priors"><i class="fa fa-check"></i>Priors</a>
<ul>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html#fixed-effects"><i class="fa fa-check"></i>Fixed effects</a></li>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html#variance-components-1"><i class="fa fa-check"></i>Variance components</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html#demonstration"><i class="fa fa-check"></i>Demonstration</a></li>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html#example-models"><i class="fa fa-check"></i>Example Models</a></li>
<li class="chapter" data-level="" data-path="bayesian.html"><a href="bayesian.html#beyond-the-model"><i class="fa fa-check"></i>Beyond the Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="further.html"><a href="further.html"><i class="fa fa-check"></i>Going Further</a>
<ul>
<li class="chapter" data-level="" data-path="further.html"><a href="further.html#other-distributions"><i class="fa fa-check"></i>Other Distributions</a></li>
<li class="chapter" data-level="" data-path="further.html"><a href="further.html#other-contexts"><i class="fa fa-check"></i>Other Contexts</a></li>
<li class="chapter" data-level="" data-path="further.html"><a href="further.html#nonlinear-mixed-effects-models"><i class="fa fa-check"></i>Nonlinear Mixed Effects Models</a></li>
<li class="chapter" data-level="" data-path="further.html"><a href="further.html#connections"><i class="fa fa-check"></i>Connections</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html"><i class="fa fa-check"></i>Supplemental</a>
<ul>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#a-comparison-to-latent-growth-curve-models"><i class="fa fa-check"></i>A Comparison to Latent Growth Curve Models</a>
<ul>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#random-effects-as-latent-variables"><i class="fa fa-check"></i>Random effects as latent variables</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#random-effects-in-sem"><i class="fa fa-check"></i>Random effects in SEM</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#running-a-growth-curve-model"><i class="fa fa-check"></i>Running a growth curve model</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#random-intercepts"><i class="fa fa-check"></i>Random intercepts</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#random-intercepts-and-slopes"><i class="fa fa-check"></i>Random intercepts and slopes</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#random-effects-with-heterogeneous-variances"><i class="fa fa-check"></i>Random effects with heterogeneous variances</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#other-covariates"><i class="fa fa-check"></i>Other covariates</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#some-differences-between-mixed-models-and-growth-curves"><i class="fa fa-check"></i>Some differences between mixed models and growth curves</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#recommended-packages-that-can-do-growth-curve-models"><i class="fa fa-check"></i>Recommended packages that can do growth curve models</a></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#summary-of-lgc"><i class="fa fa-check"></i>Summary of LGC</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#correlation-structure-revisited"><i class="fa fa-check"></i>Correlation Structure Revisited</a>
<ul>
<li class="chapter" data-level="" data-path="supplemental.html"><a href="supplemental.html#summary-of-residual-correlation-structure"><i class="fa fa-check"></i>Summary of residual correlation structure</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#data"><i class="fa fa-check"></i>Data</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#programming-languages"><i class="fa fa-check"></i>Programming languages</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#r"><i class="fa fa-check"></i>R</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#python"><i class="fa fa-check"></i>Python</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#julia"><i class="fa fa-check"></i>Julia</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#proprietary"><i class="fa fa-check"></i>Proprietary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#reference-texts-and-other-stuff"><i class="fa fa-check"></i>Reference texts and other stuff</a></li>
</ul></li>
<li class="divider"></li>
<li class='after'">
   <a href="https://m-clark.github.io/">
      <img src="img/mc_logo.png" style="width:25%; padding:0px 0; display:block; margin: 0 auto;" alt="MC logo">
   </a>
</li>
<li class='after'">
   <div style='text-align:center'>
      <a href="https://github.com/m-clark/">
         <i class="fab fa-github fa-2x" aria-hidden="true"></i>
      </a>
   </div>
</li>
<li class='after'">
   <div style='text-align:center'>
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
         <i class="fab fa-creative-commons fa-lg"></i>
         <i class="fab fa-creative-commons-by fa-lg"></i>
         <i class="fab fa-creative-commons-sa fa-lg"></i>
      </a>
   </div>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mixed Models with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="common-extensions" class="section level1">
<h1>Common Extensions</h1>
<p><br></p>
<div style="width:50%; margin:auto auto; font-size:50%">
<div id="htmlwidget-706efbc6cda3fc4604a6" style="width:100%;height:33%;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-706efbc6cda3fc4604a6">{"x":{"diagram":"digraph Factor  {\n  \n  graph [rankdir=TB  bgcolor=transparent splines=\"line\"]\n\n  subgraph cluster0 {\n    style=invis\n    node [shape=circle width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#00aaff80\" style=filled fontsize=12];\n\n    Q [label = \"\"  fillcolor=\"#396A57\"];\n\n    node [shape=square width=.25 fontcolor=\"#990024\" color=\"#990024\" fillcolor=\"#ffffff\" style=filled fontsize=12, label=\"\"];\n    edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" arrowsize=0];\n\n    Q1;\n    Q2;\n    Q3;\n    \n    Q -> Q1, Q2, Q3; \n\n\n  }\n  \n  subgraph cluster1 {\n    style=invis\n    node [shape=circle width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#00aaff80\" style=filled fontsize=12];\n\n    X [label = \"\" fillcolor=\"#667A3E\"];\n\n    node [shape=square width=.25 fontcolor=\"#990024\" color=\"#990024\" fillcolor=\"#ffffff\" style=filled fontsize=12, label=\"\"];\n    edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" arrowsize=0];\n\n    X1;\n    X2;\n    X3;\n    \n    X -> X1, X2, X3; \n\n  }\n  subgraph cluster2 {\n    style=invis\n    node [shape=circle width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#00aaff80\" style=filled fontsize=12];\n    \n    Y [label = \"\" fillcolor=\"#9C882D\"];\n\n    node [shape=triangle width=.25 fontcolor=\"#990024\" color=\"#990024\" fillcolor=\"#ffffff\" style=filled fontsize=12, label=\"\"];\n    edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" arrowsize=0];\n\n    Y1;\n    Y2;\n    Y3;\n    \n    Y -> Y1, Y2, Y3; \n\n  }\n  \n  subgraph cluster3 {\n    style=invis\n    node [shape=circle width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#00aaff80\" style=filled fontsize=12];\n    \n    Z [label = \"\"  fillcolor=\"#DA954D\"];\n\n    node [shape=diamond width=.25 fontcolor=\"#990024\" color=\"#990024\" fillcolor=\"#ffffff\" style=filled fontsize=12 label = \"\"];\n    edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" arrowsize=0];\n\n    Z1;\n    Z2;\n    Z3;\n    \n    Z -> Z1, Z2, Z3; \n  }\n  \n  node [shape=star width=.5 fontcolor=\"#fffff8\" color=\"transparent\" fillcolor=\"#00aaff80\" style=filled fontsize=12];\n  edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" arrowsize=0dir = \"back\"];\n  \n  A [label = \"\" fillcolor=\"#184E60\"];\n  B [label = \"\" fillcolor=\"#FCA68C\"];\n  \n  Q1, X2, Q3, Y1, Z2, Y3 -> A;\n  X1, Q2, X3, Z1, Y2, Z3 -> B;\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p><br></p>
<div id="additional-grouping-structure" class="section level2">
<h2>Additional Grouping Structure</h2>
<div id="cross-classified-models" class="section level3">
<h3>Cross-classified models</h3>
<p>Oftentimes there will be additional sources of variance beyond one
grouping factor. Consider as an example, a visual perception experiment
where there are multiple trials for each individual, along with specific
images displayed. Such data might look like this.</p>
<div id="htmlwidget-2c6ddc43d4a0eb69196a" style="width:250px;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2c6ddc43d4a0eb69196a">{"x":{"filter":"none","data":[[1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20],["a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j","a","b","c","d","e","f","g","h","i","j"],[5,7,1,4,9,8,1,5,1,7,1,5,10,8,9,1,2,5,5,1,9,9,4,9,1,10,10,1,9,1,2,9,3,4,8,3,6,8,5,5,4,2,8,1,10,4,7,10,2,6,9,5,4,8,9,5,9,4,10,3,3,2,4,7,10,7,8,1,4,6,9,3,5,6,5,9,7,2,1,2,8,7,10,8,10,4,7,10,9,7,4,5,10,6,5,1,8,5,4,9,1,4,3,9,10,2,4,4,2,1,4,5,10,10,9,10,9,3,8,9,9,9,9,10,5,3,8,4,9,5,10,1,6,9,7,4,8,7,10,7,10,7,5,2,3,7,10,5,7,9,2,2,6,8,1,4,7,2,2,8,6,8,10,5,3,3,7,2,10,10,2,10,2,8,9,4,1,10,10,2,5,9,5,4,2,6,5,1,4,4,4,2,1,10,3,9,7,5,9,3]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Person<\/th>\n      <th>Image<\/th>\n      <th>score<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"tp","autoWidth":false,"columnDefs":[{"width":"10px","targets":[0,1,2]},{"className":"dt-center","targets":[0,1,2]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><br> <br></p>
<p>In these situations, we have observations clustered within both person
and image, but person and image are not nested within one another- all
participants see all 10 images. Such a situation is typically referred
to as one in which there are <span class="emph">crossed</span> random effects, which just
means non-nested. In the situations we’ll look at next, we will have
multiple sources variances to consider.</p>
<div id="example-student-achievement" class="section level4">
<h4>Example: Student achievement</h4>
<p>For our own demonstration we’ll look at achievement scores for students.
The sources of dependency are due to students having gone to the same
primary or secondary schools. However, in this example, going to a
primary school doesn’t necessarily mean you’ll go to a specific
secondary school. Note also that there are no repeated measures, we see
each student only once. Here’s a quick look a the data, and for more
detail, check the <a href="appendix.html#data">appendix</a>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="extensions.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;data/pupils.RData&#39;</span>)</span></code></pre></div>
<div id="htmlwidget-f7bbcc147ba6d16d7f5d" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-f7bbcc147ba6d16d7f5d">{"x":{"filter":"none","data":[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,50,50,50],[2,1,17,3,4,4,4,17,14,22,1,5,1,20,30,15,5,15,22,19,19,7,22,8,4,15,6,23,29,6,5,14,19,19,7,22,9,2,22,14,7,1,19,6,11,8,6,14,9,14,2,17,19,15,8,29,15,9,9,5,23,12,20,4,7,7,8,19,17,5,19,22,8,30,6,11,23,4,17,14,5,4,8,3,3,19,2,1,9,14,12,3,15,22,6,11,7,2,7,12,8,2,6,3,30,8,15,9,17,19,7,1,14,2,9,6,15,3,9,8,15,3,15,23,1,1,23,14,6,7,4,20,9,23,4,23,12,1,19,12,17,24,1,9,11,4,9,16,1,4,19,10,11,5,4,4,7,10,10,7,24,19,22,17,3,8,19,22,6,1,3,6,2,12,12,19,16,6,2,19,17,2,23,2,2,24,1,23,12,22,23,8,2,11,4,24,2,29,4,3,6,12,6,19,6,22,7,5,19,14,3,19,26,12,5,17,11,14,10,24,1,25,7,10,8,10,14,6,22,25,5,7,17,14,3,19,4,2,16,1,1,12,20,2,28,19,1,26,3,5,17,14,8,22,5,14,7,30,23,17,12,14,1,4,3,5,7,16,23,8,21,16,2,25,11,8,2,25,19,19,8,2,8,8,16,5,4,21,6,2,6,21,5,26,2,25,19,25,21,7,4,14,21,3,19,11,21,23,12,17,2,13,7,2,17,13,19,6,25,27,5,16,5,21,19,3,13,4,8,10,2,14,25,8,23,6,23,14,7,1,25,19,5,23,5,4,16,27,26,17,5,21,23,21,11,22,23,14,6,23,26,11,21,25,19,13,26,27,25,2,4,16,22,13,6,15,3,11,7,28,14,2,10,11,7,13,23,19,14,7,17,27,10,19,7,3,10,16,4,26,6,28,18,25,16,10,2,11,25,10,4,21,11,18,21,11,23,22,27,27,2,25,22,11,21,19,21,23,13,5,10,2,25,27,30,26,6,2,7,26,21,27,27,11,14,13,6,21,21,19,18,19,3,16,10,3,25,10,3,13,6,28,10,8,26,7,3,27,6,14,6,23,27,18,21,7,27,2,21,28,4,19,16,19,4,25,26,1,18,27,19,2,14,30,25,27,14,1,22,3,8,27,27,22,28,28,4,28,16,6,11,11,16,5,21,19,14,10,7,14,11,7,11,14,18,28,18,6,10,28,6,8,16,23,8,16,28,13,6,19,18,11,10,21,23,21,10,16,16,22,13,18,7,21,6,14,3,13,16,27,10,14,6,8,13,3,28,6,7,10,14,22,27,26,14,18,28,26,23,28,20,13,5,21,24,16,4,22,7,21,14,16,20,25,22,14,20,14,29,11,6,16,15,28,4,28,16,26,10,10,6,5,8,21,26,22,4,18,22,10,14,28,28,24,16,28,10,11,29,18,21,14,21,10,26,27,24,8,23,14,16,18,4,27,10,29,29,16,8,5,27,21,16,14,16,11,13,13,11,4,18,14,28,16,18,11,14,4,14,11,20,27,26,11,14,29,6,13,18,21,28,6,28,7,11,25,26,6,14,5,16,13,26,4,5,24,5,29,6,22,18,6,21,8,28,18,26,10,10,24,13,5,28,28,10,24,13,8,20,11,28,15,21,1,7,20,27,3,18,29,25,13,22,18,8,27,7,1,13,7,26,8,10,24,10,28,25,26,28,20,13,9,25,15,16,18,18,29,18,18,22,22,28,11,6,27,26,24,28,28,11,21,9,10,10,10,18,29,28,20,11,29,9,27,20,30,28,29,18,18,20,16,26,9,15,27,15,5,16,27,23,16,16,24,28,24,15,18,18,9,22,6,22,9,11,27,26,26,7,6,6,28,13,25,27,11,30,24,13,13,26,16,29,29,22,29,22,6,10,1,10,27,29,30,22,29,10,24,26,9,27,15,25,16,18,13,20,29,30,26,26,21,7,17,24,22,30,18,15,17,9,7,12,10,29,10,25,27,26,30,29,16,27,25,21,13,30,16,6,13,10,7,12,17,20,29,30,29,21,24,20,12,30,20,1,30,17,15,16,30,21,21,13,15,20,18,29,30,24,24,25,10,25,22,17,29,12,7,28,30,22,29,10,27,28,21,15,30,29,29,28,7,18,21,24,20,18,28,12,29,17,25,24,12,10,1,29,15,28,12,27,29,21,7,30,13,30,30,20,10,22,29,15,30,28,28,30,17,30,27,28,12,28,25,21,1,17,9,28,13,8,12,30,22,29,29,17,13,28,28],[6.6,5.7,4.5,4.4,5.8,5,4.9,5.3,9,5.4,5.9,6.6,6.3,6.3,5.9,4.6,6.4,6.1,5,6.8,6.4,6.7,5.8,7.6,6.2,6.8,6.4,7.8,6.7,6.3,6.7,7.8,6,6.6,6.6,6.8,5.6,6.9,6.4,5.8,7.5,6.3,8.4,8.4,7.2,7.4,6.6,6.9,7.1,7.4,7,5.4,7.4,6.9,7.5,6.6,7.2,6,5,7.1,6.2,7.3,7.4,6.6,7.7,7.5,7.8,7.4,6.7,6.8,6.4,6.9,7.7,7.1,7.8,6.8,6.2,7.8,6.4,7.5,6.6,5.9,6.9,6.6,5.8,6.7,7.5,6.2,5.6,6.7,7.7,6.8,7.1,6.4,6,6.9,6,6,6.2,7.1,5.7,5.2,5.6,6.8,5.8,5.9,5.9,6.4,5.6,6.5,7.3,5.9,7.3,7.5,6.3,7.4,7.5,6.3,6.2,6,6,7.9,8.2,6.9,6.6,7.1,6.6,6.5,5.7,6,6.3,4.7,5.7,5.8,6.4,6.1,6,4.5,6.7,6.7,4.7,6.1,5.7,4.9,7.7,6,6,7.5,5.3,5.6,5.3,5.1,6.8,5.2,6.9,6.2,5.6,5.8,3.9,6.6,5,5.7,4.7,5.4,6,4.3,6.6,5.4,5.6,5.6,7.1,6.7,5.1,7.1,6.2,6.2,7.1,7.2,6.9,6.8,5.6,6.4,5.9,6.6,8.2,6.7,6.9,5.5,6.2,7.1,5.6,6.4,6.5,6.4,5.5,6.8,5.9,6.3,7.1,6.2,6.7,6.7,4.9,5.9,7.1,5.6,5.2,5.9,7.6,7,5.5,6.2,6.3,5.2,7.4,5.4,6.7,5.3,4,4,5,5.5,4.8,5.7,4.8,5.4,5.2,4.8,5.7,4.9,6.4,5.8,5.4,5.3,5.2,6.1,5.9,5.8,5.3,4.8,4.3,4.3,5.8,5.5,5.8,6.7,6.4,6.6,6.7,6.7,4.6,6.3,6.9,6.3,6.6,6.1,4.3,6.3,7.2,4.9,5.3,7.3,6.1,6.1,6.4,7.8,7.8,6.2,6.4,5.8,6.4,6.1,8.4,7.7,7.3,7.3,6.4,6.9,6.6,7.3,6.9,6.1,7.1,5.6,6.5,6.2,6.1,5.4,6.8,6.6,6.1,6.8,6.8,5.3,5.8,6.7,7.4,5.8,7.3,6.8,5.9,6.6,6.4,5.6,5.8,6.7,7.2,6.2,6.2,6.3,6.5,7.1,8.5,5.9,5.4,6.4,6.9,7.5,8.3,8,6.3,6.9,5.4,7.6,5.9,7.6,6.2,6.3,5.1,5.5,5.6,5.9,6.4,5.6,5.1,5,4.3,6.8,4.4,5,5.8,6.2,5.3,5.4,6.7,7.3,6.7,7.6,9.7,6,6,5.9,8.1,6.2,9.9,8.3,8.4,6.9,7.4,6.9,7.6,8.1,7.1,7.7,6.3,8.2,9.5,7.8,5.9,6.6,6.4,6.8,5.6,6.7,6.7,7,5.9,7.8,6.2,6.5,7.7,7.2,6.2,6.8,6.2,6.4,6.2,5.9,7.4,5.6,5.9,6,6.4,7,7,6.6,6.1,6.2,7.4,7,6.2,6.9,7.2,7.4,6.5,6.2,7.7,6.3,7.2,5.7,4.7,6.7,7.8,6,5.9,6,5.8,5.1,6.3,5.7,6.8,5.1,5.7,7.4,6.8,5.9,6.1,5.7,7.3,7.5,5,6.8,6.6,6.1,7.6,7.4,6.3,5.9,7.6,7.8,6.3,6.7,7.4,5.8,6,5.4,5.9,5.9,5.6,6,6.3,5.8,6.7,6.2,4.5,6,5.6,6.9,7,6.8,6.9,8.9,6.3,8.7,7.2,8.8,6.3,6.8,7,9.1,6.2,5.6,5.8,5.9,6.3,6.3,5.3,6.9,6.6,6.8,6.7,7.2,5.8,6.5,6.1,6.4,6.1,6,6.8,6.5,6.2,4.8,7.3,6.3,6.7,7.6,6,5.7,6.3,6.3,5.1,7,5.7,7.3,6.5,6.9,4.9,6.3,7.1,6.3,7.6,6.1,6.2,6.2,6.4,5.9,5.7,7,5.9,4.9,5.1,5,7.2,6.1,5.1,5.4,4.4,5.1,4.3,4.8,5.9,6.5,6.7,6.9,7.1,6.7,6.1,6.1,7.3,5.5,5.8,7.3,5.2,7.8,6.2,6.9,5.7,6.5,6.6,5.6,6.6,5.9,6.2,7.3,5,5,6.6,6.2,7,5.6,5.2,5.5,6,6.1,5.5,5.9,5.4,5.6,5.8,5.6,5.3,5.7,6.1,6.7,6.5,5.5,5.8,7.5,6.2,7,5.7,6.3,7.3,4.9,6.4,6.4,7,6.5,6.8,7,8.5,6.8,6.2,6.9,6.5,6.8,5.7,7.9,6.3,6.6,6.2,4.7,5.6,7.4,5.5,7.5,6.9,7.8,7,6.2,6.7,5.7,5.8,6.7,7.7,4.6,5.5,4.6,5.3,5,6.7,6.2,6.4,6.8,5.7,5.5,5.2,6.7,7.3,6.1,5.4,6.7,7,6.8,6.5,6.2,5,6.1,6.4,6.4,7.2,6,4.1,6.9,6.3,6.3,6.8,6.5,6.5,5.8,4.9,6.2,6.2,7,5.9,5.7,6.2,5.8,7.2,5.9,6,7.2,5.5,6.3,4.5,6.6,5.8,6.1,6.9,6.8,5.7,6.6,5.7,6,6.9,6,5.8,6.2,4.8,5.9,4.4,4.7,5.1,5.6,6.1,7.3,7.2,6.6,6.1,7,7.5,6.9,6.3,7.2,6.2,6.2,5.5,6,6.8,5,5.6,7.4,6.8,8.4,7.5,7.5,8.7,8.2,6.4,5.3,7.9,6.4,5.8,8.1,6.8,5.3,6.5,7.3,6.4,7.7,7.7,7.9,6.2,6.4,7.2,6.5,6.9,7.1,5.7,6.1,7,7.4,5.6,5.6,5.7,5,5.6,5.5,6.7,6.5,7.7,6.9,5.9,6.9,5.6,7.2,5.6,5.8,6.3,5.6,7.1,7.3,5.5,7.9,7.7,5,5.7,5.4,4.4,6.6,5.4,6.7,8,6.5,5.6,6.2,5.4,6.7,7,6.1,6.4,4.9,5.5,6.8,5.3,5.2,6.6,5.9,5.6,5.9,6.1,5.6,6.2,6.9,6.1,6.5,6,6.5,5.3,5,5.8,6,7,6.8,7.1,7.1,5.8,7.6,6.4,6.4,6.2,6.4,6.6,8.2,7.7,6.2,7.1,5.7,6,6.7,6.6,5.7,5.8,6.8,7.7,5.5,5.4,6.4,6.3,6.1,6.5,6.5,6.6,6.7,5.6,7.4,6.6,6.3,5.7,6.6,6.2,7.7,5.9,6,6.8,6.3,6.6,5.4,6.3,6.5,5.7,6.7,5.7,7.2,5.4,6.5,5.6,6.2,6.8,6.9,7.4,6.1,6.3,5.8,6.5,7.3,7.2,6.8,5.2,7.4,6.4,6.4,5.3,5.8,7.3,5.3,5.4,5.6,5.9,5.5,5.7,7.3,6.7,5.2,5.8,4.6,6.8,6.2,5.1,7.1,7,6.2,7.1,5.4,6.9,6.5,6.7,6,6.2,7.8,6.1,5.7,6.3,6,7.2,6.8,6.8,6.5,7.3,7.2,7.8,6.7,6,8.2,6.5,7.2,5.9,7.4,5.6,7.1,6.6,5.9,7.1,6.7,5.4,6,6.1,5.7,6.4,6.8,5.2,5.8,7.1,4.9,7.1,5.6,6.2,6.6,6.6,5.7,6.2,6.1,7.4,5.8,5.8,6.7,7.9,7.1,5.9,7.4,6.7,6.4,5.2,5.5,6.3,4.9,6.7,6.9,6.6,6.4,7.3,6.2,5.6,5.9,6.8,4.9,6.2,6.6,7.5,6.3,5.8,5.8,6.6,5.2,6.5,6.2,7.8,4.2,5.7,5.9,6.6,6.2,7.1,7.3,6.3,5.7,6.2,5.6,6.2,6.3,5.9,7.4,6.1,6.8,8.2,4.5,6.9,5.3,6.8,6.8,6.1,6.4,5.7,5.9,6.3,5.4,6.8,6.3,6.8,6],["female","male","male","male","male","female","male","female","male","male","male","male","female","male","male","female","female","female","male","female","female","female","female","male","female","male","female","female","female","female","female","female","male","male","female","male","male","male","male","male","female","male","female","male","female","female","female","female","female","female","male","male","female","male","female","male","female","female","male","male","female","male","female","male","female","male","female","male","female","female","male","female","female","female","female","male","female","female","female","female","male","female","female","female","female","male","male","male","female","male","female","male","female","female","female","male","male","female","male","male","male","female","female","female","female","male","female","female","female","female","male","female","male","female","male","female","female","female","female","female","female","female","female","female","female","male","male","male","male","male","male","male","female","female","female","female","male","male","female","female","female","female","male","male","female","female","male","female","female","male","male","male","male","male","female","female","female","female","male","female","male","male","male","male","male","male","male","female","female","male","male","male","male","female","male","female","female","female","male","female","female","female","male","male","male","female","female","male","male","male","female","female","male","female","male","female","female","male","female","female","female","male","male","female","female","female","male","female","male","female","male","female","female","male","male","male","female","female","male","male","female","male","female","male","female","male","female","female","female","female","female","female","female","male","male","male","male","male","female","male","female","male","female","male","male","female","female","male","female","female","female","male","female","male","male","male","male","male","female","female","male","male","male","male","male","male","female","female","female","female","male","female","female","female","female","female","female","female","male","female","male","female","male","male","female","male","male","male","male","female","male","male","female","male","male","female","male","female","female","male","male","female","male","female","female","male","female","female","female","male","female","male","female","female","male","male","male","female","female","female","male","male","female","female","female","female","male","male","male","female","male","female","female","male","male","male","male","female","male","male","male","female","male","female","male","female","female","male","male","male","female","male","male","male","female","male","female","female","male","female","male","female","female","male","male","male","female","female","female","male","female","male","male","male","male","female","male","female","male","male","female","female","male","male","male","male","female","female","female","male","male","female","female","female","male","female","male","male","female","male","male","male","male","male","female","male","female","male","male","male","male","female","male","male","female","male","male","female","male","female","male","male","female","female","male","female","male","male","female","female","male","male","female","male","female","male","female","female","male","male","male","female","female","female","male","female","male","male","male","male","male","female","male","male","male","male","female","female","male","male","male","female","male","male","male","female","male","male","female","female","male","female","male","female","male","male","male","male","male","female","female","male","male","female","male","male","male","male","female","male","male","male","male","female","male","male","male","male","female","male","male","male","male","female","male","female","male","female","female","male","female","male","male","female","female","female","female","female","female","male","female","female","female","female","male","male","female","male","female","male","male","male","female","female","female","male","male","male","female","male","male","male","male","female","male","male","male","female","female","female","male","male","female","male","male","female","male","male","female","male","male","female","female","male","male","male","female","female","female","male","male","female","female","female","male","male","male","female","female","male","female","female","female","male","male","female","male","female","male","female","female","female","male","female","male","male","male","male","male","male","male","male","male","female","male","female","male","male","female","male","male","male","female","female","female","male","male","female","female","female","female","female","male","female","female","male","female","male","female","female","female","female","female","male","female","male","male","male","female","female","female","female","male","male","female","male","female","female","female","male","male","male","male","female","female","male","male","male","female","female","male","male","female","female","female","male","female","female","male","male","female","male","female","male","female","male","female","male","male","male","female","female","male","male","female","female","male","male","female","male","female","male","female","female","male","male","male","male","female","female","female","female","male","female","female","female","female","female","male","male","male","male","male","male","female","male","male","male","male","male","male","female","male","female","male","male","male","male","male","male","female","male","male","male","female","male","male","female","male","male","male","male","male","female","male","female","female","male","female","female","male","male","male","female","female","female","male","male","female","male","male","male","female","female","male","female","male","male","male","male","male","female","female","female","female","female","female","male","female","male","female","female","female","male","male","female","male","female","male","female","male","female","female","male","male","male","female","female","female","male","male","male","male","male","male","male","male","male","female","female","female","female","male","female","female","male","female","female","male","female","female","female","female","male","female","male","male","female","male","male","female","female","male","female","female","male","male","female","male","female","female","male","male","male","male","male","female","male","female","female","female","male","female","female","male","female","female","male","male","male","female","female","male","male","male","female","male","male","male","male","male","female","female","male","male","male","male","male","male","female","male","male","male","female","male","male","female","female","female","female","female","male","female","male","male","male","female","female","male","male","female","male","male","female","female","male","male","male","male","female","female","female","male","male","female","female","male","female","female","female","male","male","male","female","male","male","male","female","female","female","female","male","male","female","female","female","female","female","male","female","female","male","male","male","male","female","male","male","female","female","female","male","female","female","female","female","male","male","male","male","male","female","male","male","male","male","male","female","male","female","male","female","male","female","female","male","female","male","male","female","male","male","male","male","female","female","male","female","male","female","male","female","female","male","male","male","female","male","female","male"],["highest","lowest","2","2","3","4","3","2","highest","lowest","5","5","5","4","3","3","highest","5","2","5","2","3","lowest","5","4","4","5","4","lowest","highest","4","5","5","highest","5","5","4","5","5","5","4","2","5","3","5","4","5","5","5","3","4","4","2","4","highest","4","5","4","5","3","4","5","highest","4","2","5","highest","highest","highest","highest","3","4","5","2","lowest","lowest","5","5","4","5","highest","5","lowest","5","5","highest","highest","4","2","5","5","3","2","2","3","highest","4","5","5","highest","2","2","3","4","highest","4","2","5","5","4","3","5","5","5","2","2","lowest","5","5","3","lowest","highest","3","highest","5","4","5","4","5","5","5","highest","4","5","lowest","5","highest","5","5","5","2","2","5","3","highest","lowest","5","5","4","5","5","2","5","5","5","2","4","4","highest","5","highest","3","4","highest","highest","4","5","4","2","lowest","highest","3","5","5","5","2","2","4","4","2","3","lowest","5","4","4","lowest","4","4","highest","5","3","4","5","2","5","5","2","lowest","4","4","highest","4","3","5","2","3","5","4","4","4","5","4","4","4","5","highest","4","4","3","4","highest","5","3","5","3","4","5","5","lowest","3","highest","5","3","5","5","highest","highest","highest","4","highest","4","3","4","2","4","lowest","3","3","5","5","lowest","highest","5","lowest","5","3","5","5","2","5","5","4","4","2","4","5","4","4","2","4","3","2","highest","4","3","4","5","3","highest","5","3","4","4","5","5","5","2","3","5","4","3","5","2","lowest","3","highest","5","3","5","3","3","5","3","lowest","5","3","3","5","5","2","4","highest","5","3","lowest","4","3","5","highest","5","3","highest","lowest","5","4","5","5","2","highest","5","5","lowest","5","5","5","5","5","5","lowest","highest","highest","highest","5","5","highest","4","2","5","highest","5","lowest","lowest","5","4","5","highest","5","5","4","3","4","5","lowest","5","4","highest","highest","5","5","4","lowest","highest","2","5","highest","5","3","highest","3","4","4","4","4","4","3","5","4","3","highest","3","highest","5","2","4","highest","3","4","4","2","5","4","5","2","highest","5","5","5","4","5","2","2","4","5","3","5","4","3","3","3","5","2","4","5","5","3","3","5","5","4","highest","2","5","4","3","3","highest","5","lowest","highest","5","2","highest","4","4","4","3","4","3","5","5","4","2","5","5","5","3","2","3","5","5","3","highest","4","5","5","highest","lowest","5","5","5","4","4","5","highest","3","highest","4","5","4","5","2","highest","highest","2","4","3","2","5","highest","3","highest","lowest","5","3","highest","3","5","4","3","3","3","2","4","4","5","lowest","4","2","3","4","3","5","4","highest","lowest","highest","4","highest","5","3","4","3","highest","5","4","4","5","3","4","5","4","3","5","2","5","highest","5","highest","2","5","2","5","3","highest","5","4","4","3","3","highest","5","highest","5","5","3","3","4","4","highest","5","3","3","3","2","2","5","2","5","4","3","4","2","5","2","lowest","highest","2","4","5","highest","4","2","5","5","4","3","4","3","3","4","4","5","4","3","5","2","lowest","4","5","4","4","2","2","4","5","highest","5","5","5","5","lowest","4","2","4","4","5","2","5","5","3","highest","highest","highest","4","highest","lowest","2","3","4","5","2","4","highest","5","4","5","lowest","5","2","5","4","5","highest","4","3","4","5","2","highest","highest","3","highest","highest","4","5","5","highest","highest","lowest","4","highest","4","5","2","3","5","4","3","5","4","5","3","4","highest","highest","5","2","4","highest","5","3","lowest","2","5","4","5","4","highest","5","5","5","5","3","4","4","5","3","5","3","2","lowest","highest","5","5","5","5","highest","5","4","5","3","4","4","3","highest","3","2","5","4","3","5","4","5","5","4","4","4","highest","lowest","5","3","4","highest","5","3","3","3","3","3","lowest","3","5","2","lowest","5","highest","highest","highest","5","5","5","4","5","5","5","4","5","highest","5","5","5","5","lowest","4","5","4","2","4","5","2","5","5","5","5","5","lowest","lowest","4","4","5","highest","5","4","2","highest","2","3","2","3","4","highest","5","4","3","highest","5","4","lowest","5","4","4","2","lowest","highest","5","4","5","highest","4","4","3","5","4","4","5","5","3","2","5","highest","4","5","5","5","4","4","5","2","3","4","3","5","5","4","4","lowest","4","3","5","5","3","5","5","5","4","highest","highest","4","5","3","5","5","5","5","highest","highest","2","5","5","4","highest","lowest","3","5","3","3","5","5","lowest","lowest","4","5","4","2","5","highest","4","highest","4","4","3","3","5","5","5","lowest","5","5","4","5","5","4","3","2","5","3","2","4","5","highest","3","2","4","highest","5","5","4","highest","3","4","4","4","highest","3","5","2","lowest","5","4","4","lowest","4","5","highest","4","5","3","4","5","5","highest","5","5","4","5","5","4","highest","5","3","highest","3","highest","5","highest","5","highest","3","4","5","highest","4","3","5","4","5","3","4","4","5","4","3","highest","4","4","4","5","4","5","5","5","3","2","5","3","5","5","4","5","2","4","4","highest","2","5","lowest","highest","3","4","highest","2","5","3","highest","5","2","highest","5","4","5"],["no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes"],["no","yes","no","no","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","yes","no","no","yes","yes","no","yes","yes","no","yes","yes","no","no","yes","no","yes","no","no","yes","yes","yes","no","no","yes","no","no","yes","yes","yes","no","no","no","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","yes","no","no","no","yes","no","yes","yes","yes","no","yes","yes","yes","no","no","no","no","no","yes","yes","yes","yes","no","yes","no","no","yes","yes","no","yes","yes","no","no","no","no","yes","no","yes","yes","no","no","yes","yes","yes","no","yes","no","yes","no","yes","no","yes","no","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no","yes","no","no","no","yes","yes","no","yes","no","no","no","no","no","yes","no","no","yes","yes","yes","yes","no","yes","no","no","yes","yes","yes","no","yes","yes","no","no","yes","no","no","no","no","yes","yes","no","yes","no","no","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","no","no","yes","yes","yes","no","yes","no","no","yes","no","yes","yes","yes","yes","yes","no","yes","no","yes","yes","no","yes","no","yes","no","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","no","yes","yes","yes","yes","no","yes","yes","no","yes","yes","no","no","yes","no","no","no","no","no","no","yes","yes","yes","yes","no","no","no","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","yes","no","no","yes","yes","yes","yes","no","no","yes","yes","no","no","yes","no","no","yes","no","yes","yes","yes","yes","no","no","yes","yes","no","yes","no","yes","yes","no","yes","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","no","yes","yes","no","yes","yes","yes","yes","yes","no","yes","yes","no","yes","no","yes","yes","no","yes","no","yes","no","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","no","yes","yes","no","no","yes","no","yes","no","yes","yes","yes","yes","no","yes","no","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","no","no","no","no","yes","no","yes","yes","no","yes","yes","yes","yes","yes","no","yes","no","yes","yes","no","no","yes","yes","yes","no","no","yes","yes","yes","no","yes","yes","no","no","no","no","yes","yes","no","yes","yes","no","yes","no","yes","yes","no","yes","yes","no","no","no","yes","no","yes","no","no","yes","yes","no","no","yes","yes","yes","no","yes","no","yes","yes","yes","yes","no","no","no","no","yes","yes","yes","no","yes","yes","no","no","no","no","no","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","no","no","yes","yes","no","no","yes","yes","no","yes","yes","yes","no","no","no","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","no","yes","yes","no","yes","no","yes","yes","no","yes","yes","no","no","yes","no","yes","no","yes","yes","yes","no","no","yes","yes","no","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","no","yes","no","yes","no","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","no","yes","yes","no","yes","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","no","yes","no","yes","yes","yes","no","yes","no","yes","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","no","yes","yes","yes","yes","yes","no","no","yes","yes","yes","yes","no","yes","no","yes","yes","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","yes","no","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","yes","yes","yes","yes","yes","yes","no","no","no","no","yes","yes","yes","no","no","no","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","no","yes","no","yes","yes","yes","no","no","yes","no","no","no","no","yes","yes","no","no","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","no","yes","yes","no","yes","yes","no","no","no","yes","yes","yes","no","no","no","yes","yes","no","yes","no","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","yes","no","yes","yes","yes","no","no","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","no","no","yes","yes","yes","no","yes","yes","no","yes","yes","yes","yes","no","no","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","yes","no","yes","no","yes","no","yes","no","no","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","no","no","yes","yes","yes","yes","yes","no","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","no","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","no","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","no","no","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","no","yes","no","yes","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","yes","yes","yes","yes","yes","no","yes","yes","no","yes","yes","no","yes","yes","yes","yes","yes","yes"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>PUPIL<\/th>\n      <th>primary_school_id<\/th>\n      <th>secondary_school_id<\/th>\n      <th>achievement<\/th>\n      <th>sex<\/th>\n      <th>ses<\/th>\n      <th>primary_denominational<\/th>\n      <th>secondary_denominational<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"tp","scrollX":true,"autoWidth":true,"columnDefs":[{"className":"dt-right","targets":[0,1,2,3]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><br> <br></p>
<p>For our mixed model we’ll look at the effects for <code>sex</code> and
socioeconomic status, <code>ses</code>, a six level variable from low to high, on
scholastic achievement. The range of achievement scores is roughly
4 to
10, with mean of
6.3 and standard deviation
0.9. We’ll take into account the
clustering at primary school and secondary school. To incorporate the
additional structure in <span class="pack">lme4</span> syntax is very easy, we just do as
we did before, though now for both grouping factors<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="extensions.html#cb2-1" aria-hidden="true" tabindex="-1"></a>pupils_crossed <span class="ot">=</span> <span class="fu">lmer</span>(</span>
<span id="cb2-2"><a href="extensions.html#cb2-2" aria-hidden="true" tabindex="-1"></a>  achievement <span class="sc">~</span> sex <span class="sc">+</span> ses </span>
<span id="cb2-3"><a href="extensions.html#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>primary_school_id) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>secondary_school_id),</span>
<span id="cb2-4"><a href="extensions.html#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> pupils</span>
<span id="cb2-5"><a href="extensions.html#cb2-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-6"><a href="extensions.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb2-7"><a href="extensions.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="do">## summary(pupils_crossed, correlation = FALSE)</span></span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
value
</th>
<th style="text-align:right;">
se
</th>
<th style="text-align:right;">
lower_2.5
</th>
<th style="text-align:right;">
upper_97.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
5.924
</td>
<td style="text-align:right;">
0.123
</td>
<td style="text-align:right;">
5.684
</td>
<td style="text-align:right;">
6.164
</td>
</tr>
<tr>
<td style="text-align:left;">
sexfemale
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.171
</td>
<td style="text-align:right;">
0.350
</td>
</tr>
<tr>
<td style="text-align:left;">
ses2
</td>
<td style="text-align:right;">
0.132
</td>
<td style="text-align:right;">
0.118
</td>
<td style="text-align:right;">
-0.098
</td>
<td style="text-align:right;">
0.362
</td>
</tr>
<tr>
<td style="text-align:left;">
ses3
</td>
<td style="text-align:right;">
0.098
</td>
<td style="text-align:right;">
0.110
</td>
<td style="text-align:right;">
-0.118
</td>
<td style="text-align:right;">
0.314
</td>
</tr>
<tr>
<td style="text-align:left;">
ses4
</td>
<td style="text-align:right;">
0.298
</td>
<td style="text-align:right;">
0.105
</td>
<td style="text-align:right;">
0.093
</td>
<td style="text-align:right;">
0.503
</td>
</tr>
<tr>
<td style="text-align:left;">
ses5
</td>
<td style="text-align:right;">
0.354
</td>
<td style="text-align:right;">
0.101
</td>
<td style="text-align:right;">
0.156
</td>
<td style="text-align:right;">
0.551
</td>
</tr>
<tr>
<td style="text-align:left;">
seshighest
</td>
<td style="text-align:right;">
0.616
</td>
<td style="text-align:right;">
0.110
</td>
<td style="text-align:right;">
0.401
</td>
<td style="text-align:right;">
0.832
</td>
</tr>
</tbody>
</table>
<p>The fixed effects tell us there is a positive effect of being female on
achievement, and in general, relative to lowest SES category, being in
the upper categories of SES also has a positive effect.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
primary_school_id
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.17
</td>
<td style="text-align:right;">
0.42
</td>
<td style="text-align:right;">
0.24
</td>
</tr>
<tr>
<td style="text-align:left;">
secondary_school_id
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
0.09
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.47
</td>
<td style="text-align:right;">
0.69
</td>
<td style="text-align:right;">
0.66
</td>
</tr>
</tbody>
</table>
<p>When we look at the variance components we see that primary and
secondary school contributes about
34%
of the total variance. Most of the variance attributable to school comes
from the primary school.</p>
<p>If we inspect the random effects, we can see that we now have two sets
of effects- 50 for the primary
schools, and 30 for the
secondary. Both would be incorporated into any pupil-specific
prediction.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="extensions.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(<span class="fu">ranef</span>(pupils_crossed))</span></code></pre></div>
<pre><code>## List of 2
##  $ primary_school_id  :&#39;data.frame&#39;: 50 obs. of  1 variable:
##   ..$ (Intercept): num [1:50] -0.327 0.183 0.52 0.474 0.253 ...
##   ..- attr(*, &quot;postVar&quot;)= num [1, 1, 1:50] 0.0247 0.0225 0.0244 0.0215 0.0285 ...
##  $ secondary_school_id:&#39;data.frame&#39;: 30 obs. of  1 variable:
##   ..$ (Intercept): num [1:30] -0.41069 0.08247 -0.00589 -0.06162 0.08481 ...
##   ..- attr(*, &quot;postVar&quot;)= num [1, 1, 1:30] 0.0155 0.014 0.0159 0.0131 0.0142 ...
##  - attr(*, &quot;class&quot;)= chr &quot;ranef.mer&quot;</code></pre>
<p>Let’s look at them visually using <span class="pack">merTools</span>.</p>
<p><img src="mixed_models_files/figure-html/crossed_re_plot-1.png" width="672" /></p>
<p>Note that we have the usual extensions here if desired. As an example,
we could also do random slopes for student level characteristics.</p>
</div>
</div>
<div id="hierarchical-structure" class="section level3">
<h3>Hierarchical structure</h3>
<p>Now that we have looked at cross-classified models, we can proceed to
examine hierarchical cluster structuring. In this situation we have
clusters nested within other clusters, which may be nested within still
other clusters. A typical example might be cities within counties, and
counties within states.</p>
<div id="example-nurses-and-stress" class="section level4">
<h4>Example: Nurses and stress</h4>
<p>For our demonstration we’ll use the nurses data set. Here we are
interested in the effect of a training program (<code>treatment</code>) on stress
levels (on a scale of 1-7) of nurses. In this scenario, nurses are
nested within wards, which themselves are nested within hospitals, so we
will have random effects pertaining to ward (within hospital) and
hospital. For more information see the <a href="appendix.html#data">appendix</a>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="extensions.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;data/nurses.RData&#39;</span>)</span></code></pre></div>
<div id="htmlwidget-58b29341188a2ebc0ed6" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-58b29341188a2ebc0ed6">{"x":{"filter":"none","data":[[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25],[1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4],[11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,54,54,54,54,54,54,54,54,54,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,72,72,72,72,72,73,73,73,73,73,73,73,73,73,73,74,74,74,74,74,74,74,74,74,74,81,81,81,81,81,81,81,81,81,81,82,82,82,82,82,82,82,82,82,82,83,83,83,83,83,83,83,83,83,83,84,84,84,84,84,84,84,84,84,84,91,91,91,91,91,91,91,91,91,91,92,92,92,92,92,92,92,92,92,92,93,93,93,93,93,93,93,93,93,93,94,94,94,94,94,94,94,94,94,94,101,101,101,101,101,101,101,101,101,101,102,102,102,102,102,102,102,102,102,102,103,103,103,103,103,103,103,103,103,103,104,104,104,104,104,104,104,104,104,104,111,111,111,111,111,111,111,111,111,111,111,112,112,112,112,112,112,112,112,112,112,112,113,113,113,113,113,113,113,113,113,113,114,114,114,114,114,114,114,114,114,114,114,121,121,121,121,121,121,121,121,121,121,121,121,122,122,122,122,122,122,122,122,122,122,122,122,122,123,123,123,123,123,123,123,123,123,123,123,123,123,124,124,124,124,124,124,124,124,124,124,124,124,124,131,131,131,131,131,131,131,131,131,131,131,131,131,132,132,132,132,132,132,132,132,132,132,132,132,132,133,133,133,133,133,133,133,133,133,133,133,133,133,134,134,134,134,134,134,134,134,134,134,134,134,134,141,141,141,141,141,141,141,141,141,141,141,141,141,142,142,142,142,142,142,142,142,142,142,142,142,142,143,143,143,143,143,143,143,143,143,143,143,143,144,144,144,144,144,144,144,144,144,144,144,144,151,151,151,151,151,151,151,151,151,151,151,151,151,152,152,152,152,152,152,152,152,152,152,152,153,153,153,153,153,153,153,153,153,153,153,154,154,154,154,154,154,154,154,154,154,154,161,161,161,161,161,161,161,161,161,161,161,162,162,162,162,162,162,162,162,162,162,162,163,163,163,163,163,163,163,163,163,164,164,164,164,164,164,164,164,164,171,171,171,171,171,171,171,171,171,172,172,172,172,172,172,172,172,172,173,173,173,173,173,173,173,173,173,174,174,174,174,174,174,174,174,174,181,181,181,181,181,181,181,181,181,182,182,182,182,182,182,182,182,182,182,183,183,183,183,183,183,183,183,183,183,184,184,184,184,184,184,184,184,184,184,191,191,191,191,191,191,191,191,191,191,192,192,192,192,192,192,192,192,192,192,193,193,193,193,193,193,193,193,193,193,194,194,194,194,194,194,194,194,194,194,201,201,201,201,201,201,201,201,201,201,202,202,202,202,202,202,202,202,202,202,203,203,203,203,203,203,203,203,203,203,204,204,204,204,204,204,204,204,204,204,211,211,211,211,211,211,211,211,211,211,212,212,212,212,212,212,212,212,212,212,213,213,213,213,213,213,213,213,213,213,214,214,214,214,214,214,214,214,214,214,221,221,221,221,221,221,221,221,221,222,222,222,222,222,222,222,222,222,223,223,223,223,223,223,223,223,223,224,224,224,224,224,224,224,224,224,231,231,231,231,231,231,231,231,231,232,232,232,232,232,232,232,232,232,233,233,233,233,233,233,233,233,233,234,234,234,234,234,234,234,234,234,241,241,241,241,241,241,241,241,241,242,242,242,242,242,242,242,242,242,243,243,243,243,243,243,243,243,243,244,244,244,244,244,244,244,244,244,251,251,251,251,251,251,251,251,251,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,253,253,253,254,254,254,254,254,254,254,254,254],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000],[36,45,32,57,46,60,23,32,60,45,57,47,32,42,42,53,60,33,64,37,23,61,58,52,28,52,43,64,47,62,39,46,58,34,41,56,39,60,57,50,29,57,51,25,27,53,42,43,24,48,60,27,61,33,47,50,38,28,33,52,53,31,27,57,47,41,64,45,42,25,34,36,55,33,51,60,24,31,58,60,29,24,24,46,43,24,45,64,25,55,42,58,64,47,25,50,42,60,33,51,27,43,45,53,53,37,25,32,46,57,27,55,51,24,56,31,46,57,42,53,48,25,37,47,29,41,31,52,36,39,62,42,51,29,25,50,23,60,43,43,27,28,36,60,64,64,61,27,32,28,64,55,46,45,23,55,60,39,24,61,28,34,34,25,39,64,60,58,58,32,41,61,47,60,56,47,31,47,51,61,50,37,23,56,45,23,48,46,64,47,56,51,28,61,41,37,25,25,50,64,38,39,43,28,33,39,46,25,52,45,52,33,25,36,50,57,43,53,62,60,62,33,33,27,61,23,38,64,64,57,25,56,43,45,23,46,37,31,29,37,61,43,39,29,52,58,34,57,37,56,32,29,29,32,25,36,45,58,52,42,31,37,47,31,38,58,31,41,62,62,24,28,58,56,50,51,24,28,43,45,61,45,41,31,32,24,57,41,58,56,51,45,32,55,53,41,47,41,28,62,34,41,31,57,60,29,46,27,50,45,34,45,39,43,28,55,32,38,36,29,48,31,37,58,31,46,60,46,57,50,64,24,37,36,58,64,34,47,43,39,43,27,27,55,61,37,36,32,47,27,42,55,45,23,58,60,58,33,50,47,23,53,27,53,37,53,52,39,48,64,42,31,34,41,47,48,29,51,48,61,23,61,50,39,37,47,24,47,23,36,41,55,56,37,39,24,56,60,42,29,39,61,37,24,31,36,47,64,47,31,55,34,29,42,42,56,57,29,33,39,62,60,56,47,34,39,50,38,50,25,34,39,42,42,39,56,56,31,58,43,58,37,25,57,52,36,24,42,60,56,55,31,32,42,32,32,57,61,41,46,51,31,56,42,45,39,46,36,42,41,37,52,42,57,62,32,56,48,33,34,61,24,31,46,27,42,62,57,31,34,57,53,47,34,47,31,25,57,47,61,27,53,34,64,34,55,43,29,45,27,47,58,45,64,55,32,29,29,48,45,43,23,60,39,45,36,45,36,42,37,41,64,58,62,32,33,25,60,38,48,45,56,46,45,37,57,62,24,61,51,33,60,36,52,56,46,50,32,45,28,51,38,55,45,32,43,24,47,47,45,52,45,62,48,50,46,61,58,51,33,24,60,43,57,33,62,61,47,60,27,24,31,55,53,23,25,27,45,52,25,37,50,41,28,50,52,23,28,24,37,56,58,36,58,41,51,34,58,37,25,45,58,28,43,38,38,37,61,64,47,39,45,34,34,52,33,50,45,31,53,28,50,58,39,42,28,43,64,47,29,56,23,28,43,60,62,34,36,51,53,58,57,23,23,36,39,33,45,50,34,64,31,61,48,34,58,42,51,28,64,58,37,43,33,62,39,55,43,61,52,45,57,32,32,34,32,56,57,61,23,24,42,24,57,27,51,58,29,42,43,32,51,47,62,61,47,37,23,27,55,25,43,52,25,50,50,58,34,43,46,42,51,46,25,29,48,53,29,51,62,29,46,48,37,25,38,24,27,45,41,38,57,45,57,25,43,45,38,46,46,41,45,37,53,39,51,32,25,23,41,55,24,55,50,62,46,48,53,56,46,56,29,36,31,53,52,47,56,25,56,61,64,41,56,37,36,41,25,62,27,29,36,58,46,37,32,64,52,31,52,47,39,45,53,51,50,34,48,32,38,34,62,31,50,47,27,61,48,64,28,36,51,55,31,28,33,38,45,28,38,46,57,42,31,37,57,42,42,60,33,48,24,37,37,28,34,33,50,31,29,61,58,48,25,34,27,23,58,48,50,45,51,53,25,50,29,64,36,56,34,61,34,58,60,39,24,34,48,28,34,42,46,38,31,24,56,23,50,27,60,23,25,24,37,56,42,39,29,64,50,36,46,56,31,56,64,47,32,41,41,34,37,48,62,38,24,25,36,23,24,60,41,28,58,24,34,33,55,43,57,31,23,37,55,58,55,47,47,28,33,32,52,34,56,42,29,28,55,37,47,48,31,25,47,51,34,62,39,46,38,36,25,42,36,32,42,36,51,52,31,25,41,29,23,23,38,28,62,45,60,34,41,27,39,33,56,29,32,34,58],["Male","Male","Male","Female","Female","Female","Female","Female","Male","Male","Female","Male","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Male","Female","Male","Male","Male","Female","Female","Female","Female","Male","Male","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Male","Male","Male","Female","Male","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Male","Male","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Male","Female","Male","Female","Female","Female","Male","Male","Male","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Male","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Male","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Male","Male","Female","Female","Female","Female","Male","Male","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Male","Female","Female","Female","Female","Male","Male","Female","Female","Male","Male","Female","Female","Female","Female","Male","Male","Female","Female","Male","Male","Female","Male","Female","Female","Female","Female","Male","Female","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Male","Male","Male","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Male","Female","Male","Male","Male","Female","Female","Male","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Male","Female","Male","Female","Male","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Male","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Male","Male","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Male","Male","Female","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Male","Female","Male","Male","Female","Female","Female","Female","Male","Female","Male","Male","Female","Female","Female","Male","Female","Male","Male","Female","Male","Male","Female","Female","Male","Male","Female","Male","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Male","Female","Female","Male","Male","Female","Female","Female","Male","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Male","Male","Female","Female","Male","Female","Female","Female","Female","Male","Female","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Male","Female","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Male","Male","Female","Female","Female","Male","Male","Female","Male","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Male","Male","Female","Female","Female","Female","Female","Female","Male","Male","Female","Male","Male","Female","Female","Female","Male","Female","Female","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Male","Female","Male","Female","Female","Male","Female","Male","Female","Male","Female","Female","Female","Female","Male","Female","Female","Female","Male","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Male","Male","Male","Female","Female","Male","Female","Male","Male","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Male","Female","Male","Female","Male","Female","Male","Female","Female","Female","Male","Female","Female","Male","Male","Female","Female","Female","Male","Female","Male","Female","Male","Male","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Female","Female","Female","Male","Male","Female","Male","Female","Male","Female","Male","Male","Female","Female","Female","Male","Female","Female","Male","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Female","Male","Female","Male","Female","Female","Female","Female","Female","Male","Male","Female","Female","Female","Female","Male","Male","Female","Female","Female","Male","Female","Male","Male","Female","Male","Female","Female","Female","Male","Female","Female","Female","Male","Male","Female"],[11,20,7,25,22,22,13,13,17,21,24,24,14,13,17,20,28,21,22,17,7,20,24,20,6,17,20,32,17,27,11,20,22,14,10,17,20,29,25,20,8,29,20,13,10,18,24,15,6,17,18,10,25,14,20,21,15,8,11,21,17,17,13,20,20,17,28,24,20,8,18,17,25,11,21,31,7,18,21,27,14,13,10,21,25,4,18,25,4,27,18,25,20,17,7,21,14,29,20,18,11,17,15,21,21,15,10,14,20,25,11,25,20,14,20,17,17,24,18,18,22,7,13,14,7,13,18,22,20,8,25,13,24,13,10,13,4,18,21,13,13,14,17,25,25,27,25,11,7,11,24,24,14,20,13,22,22,22,10,22,11,15,7,6,14,28,28,20,24,14,20,20,21,28,14,18,8,20,21,20,24,10,14,24,13,11,11,17,28,21,24,13,8,27,17,17,8,11,15,24,11,11,14,8,15,10,22,11,18,17,15,4,8,17,21,18,20,21,20,27,22,4,20,13,28,15,21,33,32,18,4,27,21,20,6,15,20,14,7,13,25,20,17,13,20,28,15,29,8,20,8,13,10,13,11,18,14,17,25,15,8,17,25,6,13,22,13,15,17,32,13,13,20,24,21,13,8,11,14,14,27,17,18,8,14,10,24,14,15,20,18,15,13,25,21,13,18,17,14,25,13,17,14,24,24,10,14,15,17,15,10,14,14,20,14,22,4,20,10,15,18,13,15,24,17,20,20,14,22,22,25,7,17,13,20,28,17,20,20,11,14,11,13,17,24,18,20,7,20,8,21,22,20,8,20,21,20,17,15,20,6,24,8,20,13,17,21,11,20,22,15,13,10,17,22,14,13,20,21,27,6,21,24,18,17,17,13,21,13,7,15,22,25,15,13,10,21,29,18,6,8,20,13,10,13,8,22,18,25,10,20,13,14,20,17,22,27,10,10,20,21,22,18,18,14,20,22,17,21,10,14,20,20,17,13,21,25,11,21,20,28,14,7,25,20,15,13,20,27,22,24,11,17,13,14,10,28,27,20,18,21,7,22,20,14,17,18,8,15,13,13,27,22,22,27,11,20,24,20,15,21,6,13,13,4,17,24,25,15,13,21,17,20,18,15,11,10,21,14,21,10,24,10,22,11,21,18,15,17,11,17,22,15,25,17,14,8,13,11,22,24,10,25,21,13,10,20,8,10,20,15,25,25,28,7,10,6,20,13,21,20,20,20,18,14,20,27,14,22,15,8,31,11,21,29,18,21,20,11,13,20,18,22,24,17,13,11,17,21,17,28,20,28,22,15,17,28,28,24,17,13,27,11,22,15,36,29,18,22,17,6,20,25,20,6,15,8,22,25,8,14,21,11,6,17,25,6,4,10,10,27,22,18,24,14,18,18,24,17,11,18,22,6,20,18,18,10,20,28,17,18,13,10,13,21,15,21,13,10,17,7,17,21,13,24,18,18,27,25,6,29,3,10,18,25,20,15,11,22,24,25,18,10,6,8,20,17,13,17,17,28,6,27,15,17,25,15,18,13,22,22,20,15,13,24,17,21,20,25,20,20,21,14,14,15,10,24,15,29,10,10,14,8,28,10,20,20,13,14,14,15,22,21,20,24,20,17,7,13,24,8,15,14,8,15,14,22,7,18,18,15,24,15,13,17,17,20,8,20,27,13,17,18,15,10,17,11,14,15,14,17,21,15,22,1,10,15,17,13,18,21,17,22,27,14,20,11,11,8,15,24,14,20,18,24,17,20,18,28,24,21,17,8,10,27,20,25,22,7,25,20,24,20,21,17,15,15,3,32,10,15,15,22,13,14,15,27,24,8,17,21,17,15,17,21,28,14,18,8,17,15,29,14,20,15,10,18,25,24,13,8,21,22,17,6,4,18,21,10,18,22,25,20,13,14,22,22,14,24,18,18,11,17,13,8,15,14,24,14,15,24,24,17,11,17,10,6,21,21,18,15,18,27,13,24,11,27,13,28,18,28,15,29,22,20,13,14,22,13,10,18,15,15,11,8,27,6,20,6,18,7,7,11,15,18,17,17,18,28,20,13,20,20,13,27,38,24,13,15,13,14,13,20,25,11,14,1,20,15,6,20,20,10,24,8,13,20,24,20,21,11,7,17,25,22,24,15,7,10,10,17,21,10,21,18,18,14,20,15,17,18,15,8,18,21,10,27,14,17,18,13,10,14,11,15,15,15,21,22,6,14,20,17,8,15,17,8,25,15,21,7,15,11,15,8,14,10,11,14,22],[7,7,7,6,6,6,6,7,7,6,6,6,6,6,6,5,5,6,5,5,4,4,4,4,5,5,4,4,5,4,5,5,4,5,5,5,4,5,5,5,5,5,5,5,5,4,5,4,5,5,5,4,5,5,5,4,4,6,5,4,6,5,4,6,5,4,4,5,5,5,5,5,4,5,4,4,4,5,4,5,5,3,4,3,3,4,4,4,5,3,5,6,6,6,5,5,5,5,5,6,6,6,6,6,6,6,7,6,6,5,6,5,6,5,5,5,6,5,5,5,5,5,4,5,5,5,4,5,3,6,5,6,6,5,6,6,6,6,5,6,5,6,7,5,5,5,6,5,6,6,6,6,6,5,5,5,5,5,6,6,6,5,6,6,6,5,5,6,5,6,5,5,6,6,7,5,5,6,6,5,5,5,4,4,5,4,4,4,4,4,5,5,4,3,4,4,3,3,4,3,4,6,5,5,5,5,5,5,5,5,6,6,5,5,5,6,5,5,5,4,5,5,5,4,4,4,5,4,4,5,5,5,5,5,4,5,4,5,5,5,5,5,4,5,5,5,5,5,5,5,5,4,5,4,5,5,4,5,5,6,6,5,4,6,6,6,5,5,6,5,5,5,5,5,4,6,6,5,5,5,5,6,5,5,5,6,4,5,7,5,5,6,5,5,5,6,5,5,5,2,2,3,3,1,3,2,3,2,3,3,3,3,3,3,3,3,3,2,3,4,5,5,4,5,4,4,5,5,5,4,5,5,5,5,4,4,4,5,4,6,5,6,5,6,5,6,4,5,5,6,5,6,5,5,6,5,5,5,5,6,6,6,6,6,6,7,6,6,6,6,5,5,6,5,5,6,6,5,6,4,4,4,5,4,4,4,4,4,4,4,5,4,4,4,5,4,5,4,4,4,4,5,5,5,5,6,5,5,5,4,5,5,5,5,5,6,5,6,6,5,6,6,5,4,4,3,4,3,3,4,4,4,4,4,4,4,5,5,5,4,4,5,5,4,5,4,5,5,5,5,6,6,5,6,5,6,5,5,6,5,6,6,6,5,7,5,6,6,6,6,6,6,6,4,3,3,3,4,3,3,4,4,4,4,5,4,3,4,3,4,3,3,4,3,4,4,5,4,4,5,6,6,6,4,5,5,5,4,5,5,5,6,5,4,5,5,5,5,6,5,5,6,5,5,6,3,4,4,5,3,4,4,3,4,4,4,4,3,5,5,3,4,4,4,4,5,4,4,4,5,4,4,6,5,5,5,5,4,6,5,5,5,5,5,5,5,5,5,5,5,4,5,5,6,5,4,5,4,3,5,4,4,4,4,4,3,4,4,6,5,6,6,5,6,6,6,6,5,5,5,6,6,6,5,6,5,5,5,5,5,5,7,6,7,6,6,6,6,6,6,5,4,5,4,4,5,5,4,4,4,3,5,5,5,6,5,5,4,5,5,5,5,5,6,5,6,6,5,6,6,6,7,5,5,5,6,5,6,6,6,6,5,5,6,5,5,5,5,5,4,5,5,5,5,5,5,5,5,6,5,4,5,4,5,5,4,5,5,5,6,5,5,5,5,5,4,4,5,3,4,4,4,5,3,4,4,4,4,4,4,4,4,4,4,5,4,6,6,4,5,6,6,5,6,5,6,5,6,6,6,5,5,6,6,5,6,6,6,5,6,6,6,7,5,5,5,5,5,6,6,5,6,5,5,7,6,7,5,6,6,6,6,6,6,6,5,6,5,6,6,6,6,5,5,6,6,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,4,4,4,7,7,6,6,6,7,6,7,6,6,6,6,7,7,6,6,7,6,6,5,3,3,3,2,3,2,2,2,3,3,3,2,3,4,4,4,3,3,3,4,5,4,6,4,4,4,4,5,5,5,3,5,5,5,5,4,5,5,4,5,6,6,5,6,6,5,5,6,5,5,5,6,5,6,5,5,5,5,5,6,5,6,4,6,5,5,5,6,5,5,5,5,6,6,6,6,6,7,6,7,7,7,7,7,6,6,5,6,6,5,6,6,5,6,6,6,6,6,5,5,6,6,6,5,5,5,5,6,5,5,5,4,4,4,4,3,4,4,4,4,3,5,5,6,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,5,6,6,5,6,6,5,6,6,5,6,5,6,5,6,5,6,5,5,5,6,6,5,5,7,5,5,5,6,6,5,6,6,6,7,6,6,5,7,6,6,6,6,6,6],["general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care","general care","general care","general care","general care","general care","general care","general care","general care","general care","special care","special care","special care","special care","special care","special care","special care","special care","special care"],["large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","large","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","small","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium","medium"],["Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Training","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl","Ctrl"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>hospital<\/th>\n      <th>ward<\/th>\n      <th>wardid<\/th>\n      <th>nurse<\/th>\n      <th>age<\/th>\n      <th>sex<\/th>\n      <th>experience<\/th>\n      <th>stress<\/th>\n      <th>wardtype<\/th>\n      <th>hospsize<\/th>\n      <th>treatment<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"tp","scrollX":true,"autoWidth":true,"columnDefs":[{"className":"dt-right","targets":[0,1,2,3,4,6,7]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><br> <br></p>
<p>For the model we examine effects of the treatment as well as several
other covariates, at least one at each of the nurse, ward, and hospital
levels. Again, when it comes to the fixed effects portion, you can
simply think about that part as you would any standard regression, we
just add covariates as theory/exploration would suggest. To incorporate
this type of random effects structure is not too different from the
cross-classified approach, but does have a slight change to the syntax.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="extensions.html#cb6-1" aria-hidden="true" tabindex="-1"></a>nurses_hierarchical <span class="ot">=</span> <span class="fu">lmer</span>(</span>
<span id="cb6-2"><a href="extensions.html#cb6-2" aria-hidden="true" tabindex="-1"></a>  stress <span class="sc">~</span> age <span class="sc">+</span> sex <span class="sc">+</span> experience <span class="sc">+</span> treatment <span class="sc">+</span> wardtype <span class="sc">+</span> hospsize</span>
<span id="cb6-3"><a href="extensions.html#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> hospital) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> hospital<span class="sc">:</span>ward),</span>
<span id="cb6-4"><a href="extensions.html#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> nurses</span>
<span id="cb6-5"><a href="extensions.html#cb6-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-6"><a href="extensions.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-7"><a href="extensions.html#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="do">## # same thing!</span></span>
<span id="cb6-8"><a href="extensions.html#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="do">## nurses_hierarchical = lmer(</span></span>
<span id="cb6-9"><a href="extensions.html#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   stress ~ age  + sex + experience + treatment + wardtype + hospsize </span></span>
<span id="cb6-10"><a href="extensions.html#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   + (1|hospital/ward), </span></span>
<span id="cb6-11"><a href="extensions.html#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="do">##   data = nurses</span></span>
<span id="cb6-12"><a href="extensions.html#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="do">## )</span></span>
<span id="cb6-13"><a href="extensions.html#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-14"><a href="extensions.html#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="do">## summary(nurses_hierarchical, correlation = F)</span></span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
value
</th>
<th style="text-align:right;">
se
</th>
<th style="text-align:right;">
lower_2.5
</th>
<th style="text-align:right;">
upper_97.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
5.380
</td>
<td style="text-align:right;">
0.185
</td>
<td style="text-align:right;">
5.018
</td>
<td style="text-align:right;">
5.742
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
0.022
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.018
</td>
<td style="text-align:right;">
0.026
</td>
</tr>
<tr>
<td style="text-align:left;">
sexFemale
</td>
<td style="text-align:right;">
-0.453
</td>
<td style="text-align:right;">
0.035
</td>
<td style="text-align:right;">
-0.522
</td>
<td style="text-align:right;">
-0.385
</td>
</tr>
<tr>
<td style="text-align:left;">
experience
</td>
<td style="text-align:right;">
-0.062
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
-0.070
</td>
<td style="text-align:right;">
-0.053
</td>
</tr>
<tr>
<td style="text-align:left;">
treatmentTraining
</td>
<td style="text-align:right;">
-0.700
</td>
<td style="text-align:right;">
0.120
</td>
<td style="text-align:right;">
-0.935
</td>
<td style="text-align:right;">
-0.465
</td>
</tr>
<tr>
<td style="text-align:left;">
wardtypespecial care
</td>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
0.120
</td>
<td style="text-align:right;">
-0.184
</td>
<td style="text-align:right;">
0.286
</td>
</tr>
<tr>
<td style="text-align:left;">
hospsizemedium
</td>
<td style="text-align:right;">
0.489
</td>
<td style="text-align:right;">
0.202
</td>
<td style="text-align:right;">
0.094
</td>
<td style="text-align:right;">
0.884
</td>
</tr>
<tr>
<td style="text-align:left;">
hospsizelarge
</td>
<td style="text-align:right;">
0.902
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
0.363
</td>
<td style="text-align:right;">
1.440
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>As far as the fixed effects go, about the only thing that doesn’t have a
statistical effect is ward type<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p><br></p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
hospital:ward
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.337
</td>
<td style="text-align:right;">
0.580
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
<tr>
<td style="text-align:left;">
hospital
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.119
</td>
<td style="text-align:right;">
0.345
</td>
<td style="text-align:right;">
0.177
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.217
</td>
<td style="text-align:right;">
0.466
</td>
<td style="text-align:right;">
0.323
</td>
</tr>
</tbody>
</table>
<p>Concerning the random effects, there appears to be quite a bit of
variability from ward to ward especially, but also hospital. Recall that
stress is a 7 point scale, so from ward to ward we can expect scores to
bounce around about half a point on average, which is quite dramatic in
my opinion. Again we inspect it visually.</p>
<p><img src="mixed_models_files/figure-html/hierarchical_re_plot-1.png" width="672" /></p>
</div>
</div>
<div id="crossed-vs.-nested" class="section level3">
<h3>Crossed vs. nested</h3>
<p>The following shows the difference in the results from treating ward as
a nested (within hospital) vs. crossed random effect. What do you notice
is different?</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="extensions.html#cb7-1" aria-hidden="true" tabindex="-1"></a>nurses_hierarchical <span class="ot">=</span> <span class="fu">lmer</span>(</span>
<span id="cb7-2"><a href="extensions.html#cb7-2" aria-hidden="true" tabindex="-1"></a>  stress <span class="sc">~</span> age  <span class="sc">+</span> sex <span class="sc">+</span> experience <span class="sc">+</span> treatment <span class="sc">+</span> wardtype <span class="sc">+</span> hospsize </span>
<span id="cb7-3"><a href="extensions.html#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>hospital) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>hospital<span class="sc">:</span>wardid), </span>
<span id="cb7-4"><a href="extensions.html#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> nurses</span>
<span id="cb7-5"><a href="extensions.html#cb7-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-6"><a href="extensions.html#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="extensions.html#cb7-7" aria-hidden="true" tabindex="-1"></a>nurses_crossed <span class="ot">=</span> <span class="fu">lmer</span>(</span>
<span id="cb7-8"><a href="extensions.html#cb7-8" aria-hidden="true" tabindex="-1"></a>  stress <span class="sc">~</span> age  <span class="sc">+</span> sex <span class="sc">+</span> experience <span class="sc">+</span> treatment <span class="sc">+</span> wardtype <span class="sc">+</span> hospsize </span>
<span id="cb7-9"><a href="extensions.html#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>hospital) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>wardid),</span>
<span id="cb7-10"><a href="extensions.html#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> nurses</span>
<span id="cb7-11"><a href="extensions.html#cb7-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
hospital:ward
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.337
</td>
<td style="text-align:right;">
0.580
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
<tr>
<td style="text-align:left;">
hospital
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.119
</td>
<td style="text-align:right;">
0.345
</td>
<td style="text-align:right;">
0.177
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.217
</td>
<td style="text-align:right;">
0.466
</td>
<td style="text-align:right;">
0.323
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
wardid
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.337
</td>
<td style="text-align:right;">
0.580
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
<tr>
<td style="text-align:left;">
hospital
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.119
</td>
<td style="text-align:right;">
0.345
</td>
<td style="text-align:right;">
0.177
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.217
</td>
<td style="text-align:right;">
0.466
</td>
<td style="text-align:right;">
0.323
</td>
</tr>
</tbody>
</table>
<p>Nothing? Good, you’re not crazy. Here’s a quote from the <a href="http://lme4.r-forge.r-project.org/book/Ch2.pdf">lme4
text</a>, section 2.2.1.1,
which is definitely worth your time.</p>
<blockquote>
<p>The blurring of mixed-effects models with the concept of multiple,
hierarchical levels of variation results in an unwarranted emphasis on
‘levels’ when defining a model and leads to considerable confusion. It
is perfectly legitimate to define models having random effects
associated with non-nested factors. The reasons for the emphasis on
defining random effects with respect to nested factors only are that
such cases do occur frequently in practice, and that some of the
computational methods for estimating the parameters in the models can
only be easily applied to nested factors.</p>
<p>This is not the case for the methods used in the lme4 package. <em>Indeed
there is nothing special done for models with random effects for
nested factors</em>. When random effects are associated with multiple
factors, exactly the same computational methods are used whether the
factors form a nested sequence or are partially crossed or are
completely crossed.</p>
</blockquote>
<p>You might have noticed that we were using <code>wardid</code> rather than the
<code>ward</code> grouping variable as in our first example. Even though every ward
is unique, the <code>ward</code> column labels them with an arbitrary sequence
starting with 1. While this might seem natural, ward 1 in hospital 1 is
not the same as ward 1 in hospital 2, so it’s probably not a good idea
to give them the same label. The <code>wardid</code> column properly distinguishes
the wards with unique values (e.g. 11, 12).</p>
<p>What would have happened had we used that variable as a crossed random
effect?</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="extensions.html#cb8-1" aria-hidden="true" tabindex="-1"></a>nurses_crossed_bad_data <span class="ot">=</span> <span class="fu">lmer</span>(</span>
<span id="cb8-2"><a href="extensions.html#cb8-2" aria-hidden="true" tabindex="-1"></a>  stress <span class="sc">~</span> age  <span class="sc">+</span> sex <span class="sc">+</span> experience <span class="sc">+</span> treatment <span class="sc">+</span> wardtype <span class="sc">+</span> hospsize </span>
<span id="cb8-3"><a href="extensions.html#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>hospital) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>ward), </span>
<span id="cb8-4"><a href="extensions.html#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> nurses</span>
<span id="cb8-5"><a href="extensions.html#cb8-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## boundary (singular) fit: see ?isSingular</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
hospital
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.196
</td>
<td style="text-align:right;">
0.442
</td>
<td style="text-align:right;">
0.297
</td>
</tr>
<tr>
<td style="text-align:left;">
ward
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.463
</td>
<td style="text-align:right;">
0.681
</td>
<td style="text-align:right;">
0.703
</td>
</tr>
</tbody>
</table>
<p>This is certainly not the result we want. The variance in <code>ward</code> is
already captured by treatment and type. However, as demonstrated, this
can be avoided with the proper syntax, or proper labeling in the data to
allow unique clusters to have unique identifiers.</p>
<p>See this <a href="https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified">discussion
also</a>,
as well as <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#nested-or-crossed">this from the
FAQ</a>
from one of the <span class="pack">lme4</span> developers. Josh Errickson at CSCAR also
has a nice <a href="http://errickson.net/stats-notes/vizrandomeffects.html">write-up with visual
depiction</a> of
the underlying matrices of interest, which served as inspiration for
some of the visualization in the next section.</p>
<p>So there you have it. When it comes to <span class="pack">lme4</span>, or mixed models
more generally, crossed vs. nested is simply a state of mind
(data)<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
</div>
</div>
<div id="residual-structure" class="section level2">
<h2>Residual Structure</h2>
<p>Sometimes we will want to obtain more specific estimates regarding the
residual covariance/correlation structure. This is especially the case
in the longitudinal setting, where we think that observations closer in
time would be more strongly correlated than those further apart, or that
the variance changes over time. What does this model look like?</p>
<p>Let’s begin by thinking about the covariance/correlation matrix for the
entire set of observations for our target variable, and how we want to
represent the dependency in those observations. I’ll show a
visualization of the first 5 people from our GPA data and modeling
situation. Recall that each person has 6 observations. This display
regards the results from our random intercepts (only) model for GPA.</p>
<p><img src="mixed_models_files/figure-html/residual_varcov-1.png" width="672" /></p>
<p>Each block represents the covariance matrix pertaining to observations
within an individual. Within the person there are variances on the
diagonal and covariances on the off-diagonal. When considering the whole
data, we can see that observations from one person have no covariance
with another person (gray). Furthermore, the covariance within a person
is a constant value, the variance is also a constant value. Where did
those values come from?</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
student
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.064
</td>
<td style="text-align:right;">
0.252
</td>
<td style="text-align:right;">
0.523
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.058
</td>
<td style="text-align:right;">
0.241
</td>
<td style="text-align:right;">
0.477
</td>
</tr>
</tbody>
</table>
<p>Remember that there are two sources of variance in this model, the
residual observation level variance, and that pertaining to person.
Combined they provide the total residual variance that we aren’t already
capturing with our covariates. In this case, it’s about
0.12, the value displayed on our diagonal. The
off-diagonal is the variance attributable to student, which we
alternately interpreted as an intraclass correlation (dividing by the
total variance converts it to the correlation metric).</p>
<p>More generically, and referring to previous notation for our estimated
variances, we can see the covariance matrix (for a cluster) as follows.</p>
<p><span class="math display">\[\Sigma = 
\left[
\begin{array}{ccc} 
\color{orange}{\sigma^2 + \tau^2} &amp; \tau^2   &amp; \tau^2  &amp; \tau^2 &amp; \tau^2 &amp; \tau^2   \\
\tau^2   &amp; \color{orange}{\sigma^2 + \tau^2} &amp; \tau^2 &amp; \tau^2 &amp; \tau^2 &amp; \tau^2    \\
\tau^2   &amp; \tau^2   &amp; \color{orange}{\sigma^2 + \tau^2} &amp; \tau^2 &amp; \tau^2 &amp; \tau^2  \\
\tau^2   &amp; \tau^2   &amp; \tau^2 &amp; \color{orange}{\sigma^2 + \tau^2} &amp; \tau^2 &amp; \tau^2\\
\tau^2   &amp; \tau^2   &amp; \tau^2  &amp; \tau^2 &amp; \color{orange}{\sigma^2 + \tau^2}  &amp; \tau^2 \\
\tau^2   &amp; \tau^2   &amp; \tau^2  &amp; \tau^2   &amp; \tau^2  &amp; \color{orange}{\sigma^2 + \tau^2} \\
\end{array}\right]\]</span> <br></p>
<p>This represents a covariance structure of <span class="emph">compound symmetry</span>. It
is the default in most mixed model settings, and the same as what is
shown visually above. Now let’s start to think about other types of
covariance structures.</p>
<p>Consider the following model for an individual and just three time
points to keep things simpler to show.</p>
<p><span class="math display">\[\boldsymbol{y} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})\]</span></p>
<p>So we have three observations of <span class="math inline">\(y\)</span> that are multivariate normally
distributed. The mean <span class="math inline">\(\mu\)</span> is a function of covariates just like in
standard regression.</p>
<p><span class="math display">\[\mu = b_0 + b_1\cdot \mathrm{time} + b_2\cdot x_1 ...\]</span></p>
<p>However, instead of just plopping an <span class="math inline">\(\epsilon\)</span> at the end, we want to
go further in defining the entire residual variance/covariance structure
for all three time points.</p>
<p>In the simplest setting of a standard linear regression model, we have
constant variance and no covariance.</p>
<p><span class="math display">\[\Sigma = 
\left[
\begin{array}{ccc} 
\sigma^2 &amp; 0   &amp; 0   \\
0   &amp; \sigma^2 &amp; 0   \\
0   &amp; 0   &amp; \sigma^2 \\
\end{array}\right]\]</span></p>
<p>Next, we can relax the assumption of equal variances, and estimate each
separately. In this case of heterogeneous variances, we might see more
or less variance over time, for example.</p>
<p><span class="math display">\[\Sigma = 
\left[
\begin{array}{ccc} 
\sigma_1^2 &amp; 0   &amp; 0   \\
0   &amp; \sigma_2^2 &amp; 0   \\
0   &amp; 0   &amp; \sigma_3^2 \\
\end{array}\right]\]</span></p>
<p>Now let’s say we actually want to get at the underlying
covariance/correlation. I’ll switch to the correlation representation,
but you can still think of the variances as constant or separately
estimated. So now we have something like this, where <span class="math inline">\(\rho\)</span> represents
the residual correlation among observations.</p>
<p><span class="math display">\[\Sigma = \sigma^2
\left[
\begin{array}{ccc} 
1 &amp; \rho_1   &amp; \rho_2   \\
\rho_1   &amp; 1 &amp; \rho_3   \\
\rho_2   &amp; \rho_3   &amp; 1 \\
\end{array}\right]\]</span></p>
<p>In this case we’d estimate a different correlation for all time point
pairs (with constant variance). This is typically described as an
<span class="emph">unstructured</span>, or simply ‘symmetric,’ correlation structure.</p>
<p>If you are familiar with repeated measures ANOVA, which is a <a href="https://m-clark.github.io/docs/mixedModels/anovamixed.html">special
case of a mixed
model</a>, you
may recall that the usual assumption is a <span class="emph">sphericity</span>, a relaxed
form of <span class="emph">compound symmetry</span>, where all the correlations have the
same value, i.e. <span class="math inline">\(\rho_1=\rho_2=\rho_3\)</span>, and all variances are equal.</p>
<p>Another very commonly used correlation structure (for time-based
settings) is an <span class="emph">autocorrelation</span> structure, of lag order one,
for the residuals. What this means is that we assume the residuals at
one time point apart correlate with some value <span class="math inline">\(\rho\)</span>, observations at
two time points apart correlate <span class="math inline">\(\rho^2\)</span>, and so on. As such we only
need to estimate <span class="math inline">\(\rho\)</span>, while the rest are then automatically
determined. Here’s what it’d look like for four time points.</p>
<p><span class="math display">\[\Sigma = \sigma^2
\left[
\begin{array}{cccc} 
1 &amp; \rho     &amp; \rho^2   &amp; \rho^3   \\
\rho     &amp; 1 &amp; \rho     &amp; \rho^2   \\
\rho^2   &amp; \rho     &amp; 1 &amp; \rho     \\
\rho^3   &amp; \rho^2   &amp; \rho     &amp; 1 \\
\end{array}\right]\]</span></p>
<p>If <span class="math inline">\(\rho\)</span> was estimated to be .5, it would look like the following.</p>
<p><span class="math display">\[\Sigma = \sigma^2
\left[
\begin{array}{cccc} 
1 &amp; .5       &amp; .25      &amp; .06   \\
.5       &amp; 1 &amp; .5       &amp; .25  \\
.25      &amp; .5       &amp; 1 &amp; .5    \\
.06      &amp; .25      &amp;  .5      &amp; 1 \\
\end{array}\right]\]</span></p>
<p>Again, the main point is that points further apart in time are assumed
to have less correlation.</p>
<p>Know that there are many patterns and possibilities to potentially
consider, and that they are not limited to the repeated measures
scenario. For example, the correlation could represent spatial
structure, where units closer together geographically would be more
correlated. And as noted, we could also have variances that are
different at each time point<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. We’ll start with that for
the next example.</p>
<div id="heterogeneous-variance" class="section level3">
<h3>Heterogeneous variance</h3>
<p>Unfortunately, <span class="pack">lme4</span> does not provide the ability to model the
residual covariance structure, at least <a href="https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html">not in a straightforward
fashion</a>,
though many other mixed model packages do<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. In fact, two
packages that come with the basic R installation do so, <span class="pack">mgcv</span>
and <span class="pack">nlme</span>. We’ll demonstrate with the latter.</p>
<p>The <span class="pack">nlme</span> package will have a different random effect
specification, though not <em>too</em> different. In addition, to estimate
heterogeneous variances, we’ll need to use an additional <code>weights</code>
argument. The following will allow each time point of occasion to have a
unique estimate.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="extensions.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nlme)</span>
<span id="cb10-2"><a href="extensions.html#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="extensions.html#cb10-3" aria-hidden="true" tabindex="-1"></a>heterovar_res <span class="ot">=</span> <span class="fu">lme</span>(</span>
<span id="cb10-4"><a href="extensions.html#cb10-4" aria-hidden="true" tabindex="-1"></a>  gpa <span class="sc">~</span> occasion,</span>
<span id="cb10-5"><a href="extensions.html#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> gpa,</span>
<span id="cb10-6"><a href="extensions.html#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span> <span class="sc">|</span> student,</span>
<span id="cb10-7"><a href="extensions.html#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">weights =</span> <span class="fu">varIdent</span>(<span class="at">form =</span> <span class="sc">~</span> <span class="dv">1</span> <span class="sc">|</span> occasion)</span>
<span id="cb10-8"><a href="extensions.html#cb10-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-9"><a href="extensions.html#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="extensions.html#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="do">## summary(heterovar_res)</span></span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
value
</th>
<th style="text-align:right;">
se
</th>
<th style="text-align:right;">
z
</th>
<th style="text-align:right;">
p_value
</th>
<th style="text-align:right;">
lower_2.5
</th>
<th style="text-align:right;">
upper_97.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
2.599
</td>
<td style="text-align:right;">
0.026
</td>
<td style="text-align:right;">
99.002
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.547
</td>
<td style="text-align:right;">
2.650
</td>
</tr>
<tr>
<td style="text-align:left;">
occasion
</td>
<td style="text-align:right;">
0.106
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
26.317
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.098
</td>
<td style="text-align:right;">
0.114
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
student
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.094
</td>
<td style="text-align:right;">
0.306
</td>
<td style="text-align:right;">
0.404
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.138
</td>
<td style="text-align:right;">
0.372
</td>
<td style="text-align:right;">
0.596
</td>
</tr>
</tbody>
</table>
<p>At this point we’re getting the same stuff we’re used to. Now the not-so
fun part. For the values we’re interested in for this example, i.e. the
variances at each occasion, <span class="pack">nlme</span> does not make it easy on
someone to understand initially, as the output regards the way things
are for estimation, not for what one would usually have to report. The
variances are scaled relative to the first variance estimate, which is
actually the reported residual variance in the random effects part.
Additionally the values are also on the standard deviation rather than
variance scale. From the default output display, we can see that
variance decreases over time in this case, but the actual values are not
provided.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="extensions.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(heterovar_res<span class="sc">$</span>modelStruct)</span></code></pre></div>
<pre><code>## Random effects:
##  Formula: ~1 | student
##         (Intercept) Residual
## StdDev:   0.8232544        1
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | occasion 
##  Parameter estimates:
##         0         1         2         3         4         5 
## 1.0000000 0.8261186 0.6272415 0.4311126 0.3484013 0.4324628</code></pre>
<p>Relative values are fine, I guess, but what we’d want are the actual
estimates. Here’s how you can get them using the residual standard
deviation to scale those values, then square them to get on the variance
scale.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="extensions.html#cb13-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">c</span>(<span class="fl">1.0000000</span>, <span class="fu">coef</span>(heterovar_res<span class="sc">$</span>modelStruct<span class="sc">$</span>varStruct, <span class="at">unconstrained=</span>F))<span class="sc">*</span>heterovar_res<span class="sc">$</span>sigma)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>##                     1          2          3          4          5 
## 0.13815037 0.09428374 0.05435276 0.02567636 0.01676917 0.02583744</code></pre>
<p>Yeah. You’ll have to look this up every time you want to do it, or just
make your own function that takes the model input. Here is how my
function would extract the information.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="extensions.html#cb15-1" aria-hidden="true" tabindex="-1"></a>mixedup<span class="sc">::</span><span class="fu">extract_het_var</span>(heterovar_res, <span class="at">scale =</span> <span class="st">&#39;var&#39;</span>)</span></code></pre></div>
<pre><code>##      X0    X1    X2    X3    X4    X5
## 1 0.138 0.094 0.054 0.026 0.017 0.026</code></pre>
<p>A newer alternative to keep in mind is <span class="pack">glmmTMB</span>. It would allow
one to stay more in the <span class="pack">lme4</span> style and output.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="extensions.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmmTMB)</span>
<span id="cb17-2"><a href="extensions.html#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="extensions.html#cb17-3" aria-hidden="true" tabindex="-1"></a>heterovar_res2 <span class="ot">=</span> <span class="fu">glmmTMB</span>(</span>
<span id="cb17-4"><a href="extensions.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  gpa <span class="sc">~</span> occasion <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>student) <span class="sc">+</span> <span class="fu">diag</span>(<span class="dv">0</span> <span class="sc">+</span> occas <span class="sc">|</span>student), </span>
<span id="cb17-5"><a href="extensions.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> gpa</span>
<span id="cb17-6"><a href="extensions.html#cb17-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Warning in Matrix::sparseMatrix(dims = c(0, 0), i = integer(0), j =
## integer(0), : &#39;giveCsparse&#39; has been deprecated; setting &#39;repr = &quot;T&quot;&#39; for you

## Warning in Matrix::sparseMatrix(dims = c(0, 0), i = integer(0), j =
## integer(0), : &#39;giveCsparse&#39; has been deprecated; setting &#39;repr = &quot;T&quot;&#39; for you

## Warning in Matrix::sparseMatrix(dims = c(0, 0), i = integer(0), j =
## integer(0), : &#39;giveCsparse&#39; has been deprecated; setting &#39;repr = &quot;T&quot;&#39; for you</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="extensions.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(heterovar_res2)</span></code></pre></div>
<pre><code>##  Family: gaussian  ( identity )
## Formula:          gpa ~ occasion + (1 | student) + diag(0 + occas | student)
## Data: gpa
## 
##      AIC      BIC   logLik deviance df.resid 
##    261.1    312.0   -120.5    241.1     1190 
## 
## Random effects:
## 
## Conditional model:
##  Groups    Name                   Variance Std.Dev. Corr                    
##  student   (Intercept)            0.093123 0.30516                          
##  student.1 occasyear 1 semester 1 0.129833 0.36032                          
##            occasyear 1 semester 2 0.086087 0.29341  0.00                    
##            occasyear 2 semester 1 0.046240 0.21503  0.00 0.00               
##            occasyear 2 semester 2 0.017615 0.13272  0.00 0.00 0.00          
##            occasyear 3 semester 1 0.008709 0.09332  0.00 0.00 0.00 0.00     
##            occasyear 3 semester 2 0.017730 0.13316  0.00 0.00 0.00 0.00 0.00
##  Residual                         0.008065 0.08980                          
##  
##  
##  
##  
##  
##  
##  
##  
##  
## Number of obs: 1200, groups:  student, 200
## 
## Dispersion estimate for gaussian family (sigma^2): 0.00806 
## 
## Conditional model:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 2.598788   0.026201   99.19   &lt;2e-16 ***
## occasion    0.106141   0.004034   26.31   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Note that the variances displayed for each time point are not conflated
with the residual variance. To compare with <span class="pack">nlme</span>, just add the
residual variance to those estimates. As with every mixed model package
(apparently), it still takes a bit to get the variances in a usable form
from the <span class="func">VarCorr</span> object. The following shows how though, and
compares to the <span class="pack">nlme</span> result.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="extensions.html#cb21-1" aria-hidden="true" tabindex="-1"></a>vc_glmmtmb <span class="ot">=</span> <span class="fu">VarCorr</span>(heterovar_res2)</span>
<span id="cb21-2"><a href="extensions.html#cb21-2" aria-hidden="true" tabindex="-1"></a>vc_glmmtmb <span class="ot">=</span> <span class="fu">attr</span>(vc_glmmtmb<span class="sc">$</span>cond<span class="sc">$</span>student<span class="fl">.1</span>, <span class="st">&#39;stddev&#39;</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">sigma</span>(heterovar_res2)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<p>Here is the output from my function:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="extensions.html#cb22-1" aria-hidden="true" tabindex="-1"></a>mixedup<span class="sc">::</span><span class="fu">extract_het_var</span>(heterovar_res2, <span class="at">scale =</span> <span class="st">&#39;var&#39;</span>)</span></code></pre></div>
<pre><code>##       group occasyear.1.semester.1 occasyear.1.semester.2
## 1 student.1                  0.138                  0.094
##   occasyear.2.semester.1 occasyear.2.semester.2 occasyear.3.semester.1
## 1                  0.054                  0.026                  0.017
##   occasyear.3.semester.2
## 1                  0.026</code></pre>
<p>In any case, putting these together shows we get the same result.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
year 1 sem 1
</th>
<th style="text-align:right;">
year 1 sem 2
</th>
<th style="text-align:right;">
year 2 sem 1
</th>
<th style="text-align:right;">
year 2 sem 2
</th>
<th style="text-align:right;">
year 3 sem 1
</th>
<th style="text-align:right;">
year 3 sem 2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
glmmTMB
</td>
<td style="text-align:right;">
0.138
</td>
<td style="text-align:right;">
0.094
</td>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
0.026
</td>
<td style="text-align:right;">
0.017
</td>
<td style="text-align:right;">
0.026
</td>
</tr>
<tr>
<td style="text-align:left;">
nlme
</td>
<td style="text-align:right;">
0.138
</td>
<td style="text-align:right;">
0.094
</td>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
0.026
</td>
<td style="text-align:right;">
0.017
</td>
<td style="text-align:right;">
0.026
</td>
</tr>
</tbody>
</table>
</div>
<div id="autocorrelation" class="section level3">
<h3>Autocorrelation</h3>
<p>The following example shows the same basic model, but with the
autocorrelation structure we described previously. In <span class="pack">nlme</span> we
use the built-in <span class="func">corAR1</span> function and <code>correlation</code> argument
similar to how we did with the weights argument.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="extensions.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nlme)</span>
<span id="cb24-2"><a href="extensions.html#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="extensions.html#cb24-3" aria-hidden="true" tabindex="-1"></a>corr_res <span class="ot">=</span> <span class="fu">lme</span>(</span>
<span id="cb24-4"><a href="extensions.html#cb24-4" aria-hidden="true" tabindex="-1"></a>  gpa <span class="sc">~</span> occasion,</span>
<span id="cb24-5"><a href="extensions.html#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> gpa,</span>
<span id="cb24-6"><a href="extensions.html#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span> <span class="sc">|</span> student,</span>
<span id="cb24-7"><a href="extensions.html#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">correlation =</span> <span class="fu">corAR1</span>(<span class="at">form =</span> <span class="sc">~</span> occasion)</span>
<span id="cb24-8"><a href="extensions.html#cb24-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-9"><a href="extensions.html#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="extensions.html#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="do">## summary(corr_res)</span></span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
value
</th>
<th style="text-align:right;">
se
</th>
<th style="text-align:right;">
z
</th>
<th style="text-align:right;">
p_value
</th>
<th style="text-align:right;">
lower_2.5
</th>
<th style="text-align:right;">
upper_97.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
2.597
</td>
<td style="text-align:right;">
0.023
</td>
<td style="text-align:right;">
113.146
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.552
</td>
<td style="text-align:right;">
2.642
</td>
</tr>
<tr>
<td style="text-align:left;">
occasion
</td>
<td style="text-align:right;">
0.107
</td>
<td style="text-align:right;">
0.005
</td>
<td style="text-align:right;">
20.297
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.097
</td>
<td style="text-align:right;">
0.118
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
var_prop
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
student
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.215
</td>
<td style="text-align:right;">
0.381
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
0.075
</td>
<td style="text-align:right;">
0.273
</td>
<td style="text-align:right;">
0.619
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Notice first that the fixed effect for occasion is the same as
<a href="supplemental.html#mixed-model-1">before</a>. The variance estimates have changed slightly
along with the variances of the fixed effects (i.e. the standard
errors). The main thing is that we have a new parameter called <code>Phi</code> in
the <span class="pack">nlme</span> output that represents our autocorrelation, <code>Phi</code>,
with value of
0.418. This
suggests at least some correlation exists among the residuals for
observations next to each other in time, though it diminishes quickly as
observations grow further apart.</p>
<p>Note that glmmTMB will analyze such structure as well. Note that we need
the factor form for occasion for this specification, and also note how
it is part of model formula, like another random effect. More on this in
the <a href="supplemental.html#correlation-structure-revisited">supplemental section</a>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="extensions.html#cb25-1" aria-hidden="true" tabindex="-1"></a>corr_res_tmb <span class="ot">=</span> <span class="fu">glmmTMB</span>(</span>
<span id="cb25-2"><a href="extensions.html#cb25-2" aria-hidden="true" tabindex="-1"></a>  gpa <span class="sc">~</span> occasion <span class="sc">+</span>  <span class="fu">ar1</span>(<span class="dv">0</span> <span class="sc">+</span> occas <span class="sc">|</span> student) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> student),</span>
<span id="cb25-3"><a href="extensions.html#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> gpa</span>
<span id="cb25-4"><a href="extensions.html#cb25-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div id="generalized-linear-mixed-models" class="section level2">
<h2>Generalized Linear Mixed Models</h2>
<p>Just as generalized linear models extend the standard linear model, we
can generalize (linear) mixed models to <span class="emph">generalized linear mixed
models</span>. Furthermore, there is nothing restricting us to only the
exponential family, as other packages would potentially allow for many
other response distributions.</p>
<p>For this example we’ll do a logistic regression in the mixed model
setting. In this case, we’ll use the speed dating data set. In the speed
dating events, the experiment randomly assigned each participant to ten
short dates (four minutes) with other participants. For each date, each
person rated six attributes (attractive, sincere, intelligent, fun,
ambitious, shared interests) of the other person on a 10-point scale and
wrote down whether he or she would like to see the other person again.</p>
<p>Our target variable is whether the participant would be willing to date
the person again (<code>decision</code>). To keep things simple, the predictors
will be limited to the sex of the participant (<code>sex</code>), whether the
partner was of the same race (<code>samerace</code>), and three of the attribute
ratings the participant gave of their partner- attractiveness
(<code>attractive</code>), sincerity (<code>sincere</code>), and intelligence (<code>intelligent</code>).
The latter have been scaled to have zero mean and standard deviation of
.5, which puts them on a more even footing with the binary covariates
(<code>_sc</code>)<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="extensions.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;data/speed_dating.RData&#39;</span>)</span>
<span id="cb26-2"><a href="extensions.html#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="extensions.html#cb26-3" aria-hidden="true" tabindex="-1"></a>sd_model <span class="ot">=</span> <span class="fu">glmer</span>(</span>
<span id="cb26-4"><a href="extensions.html#cb26-4" aria-hidden="true" tabindex="-1"></a>  decision <span class="sc">~</span> sex <span class="sc">+</span> samerace <span class="sc">+</span> attractive_sc <span class="sc">+</span> sincere_sc <span class="sc">+</span> intelligent_sc</span>
<span id="cb26-5"><a href="extensions.html#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> iid),</span>
<span id="cb26-6"><a href="extensions.html#cb26-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data   =</span> speed_dating,</span>
<span id="cb26-7"><a href="extensions.html#cb26-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> binomial</span>
<span id="cb26-8"><a href="extensions.html#cb26-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-9"><a href="extensions.html#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="extensions.html#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sd_model, <span class="at">correlation =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
value
</th>
<th style="text-align:right;">
se
</th>
<th style="text-align:right;">
z
</th>
<th style="text-align:right;">
p_value
</th>
<th style="text-align:right;">
lower_2.5
</th>
<th style="text-align:right;">
upper_97.5
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
-0.743
</td>
<td style="text-align:right;">
0.121
</td>
<td style="text-align:right;">
-6.130
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
-0.981
</td>
<td style="text-align:right;">
-0.506
</td>
</tr>
<tr>
<td style="text-align:left;">
sexMale
</td>
<td style="text-align:right;">
0.156
</td>
<td style="text-align:right;">
0.164
</td>
<td style="text-align:right;">
0.954
</td>
<td style="text-align:right;">
0.34
</td>
<td style="text-align:right;">
-0.165
</td>
<td style="text-align:right;">
0.478
</td>
</tr>
<tr>
<td style="text-align:left;">
sameraceYes
</td>
<td style="text-align:right;">
0.314
</td>
<td style="text-align:right;">
0.075
</td>
<td style="text-align:right;">
4.192
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.167
</td>
<td style="text-align:right;">
0.460
</td>
</tr>
<tr>
<td style="text-align:left;">
attractive_sc
</td>
<td style="text-align:right;">
1.957
</td>
<td style="text-align:right;">
0.058
</td>
<td style="text-align:right;">
33.560
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
1.842
</td>
<td style="text-align:right;">
2.071
</td>
</tr>
<tr>
<td style="text-align:left;">
sincere_sc
</td>
<td style="text-align:right;">
0.311
</td>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
5.747
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.205
</td>
<td style="text-align:right;">
0.417
</td>
</tr>
<tr>
<td style="text-align:left;">
intelligent_sc
</td>
<td style="text-align:right;">
0.444
</td>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
8.232
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.338
</td>
<td style="text-align:right;">
0.550
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>The fixed effects results are as expected for the attributes, with
attractiveness being a very strong effect in particular. In addition,
having a partner of the same race had a positive effect, while sex of
the participant was statistically negligible. You are free to
exponentiate the coefficients to get the odds ratios if desired, just as
you would with standard logistic regression.</p>
<p><br></p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:left;">
effect
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
sd
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
iid
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
2.708
</td>
<td style="text-align:right;">
1.645
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>For the variance components, notice that there is no residual variance.
This is because we are not modeling with the normal distribution for the
response, thus there is no <span class="math inline">\(\sigma\)</span> to estimate. However, the result
suggests that there is quite a bit of variability from person to person.</p>
</div>
<div id="exercises-for-extensions" class="section level2">
<h2>Exercises for Extensions</h2>
<div id="sociometric-data" class="section level3">
<h3>Sociometric data</h3>
<p>In the following data, kids are put into different groups and rate each
other in terms of how much they would like to share some activity with
the others. We have identifying variables for the person doing the
rating (sender), the person being rated (receiver), what group they are
in, as well as age and sex for both sender and receiver, as well as
group size.</p>
<p>To run a mixed model, we will have three sources of structure to
consider:</p>
<ul>
<li>senders (within group)</li>
<li>receivers (within group)</li>
<li>group</li>
</ul>
<p>First, load the sociometric data.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="extensions.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;data/sociometric.RData&#39;</span>)</span></code></pre></div>
<p>To run the model, we will proceed with the following modeling steps. For
each, make sure you are creating a separate model object for each model
run.</p>
<ul>
<li>Model 1: No covariates, only sender and receiver random effects.
Note that even though we don’t add group yet, still use the nesting
approach to specify the effects (e.g. <code>1|group:receiver</code>)</li>
<li>Model 2: No covariates, add group random effect</li>
<li>Model 3: Add all covariates: <code>agesend/rec</code>, <code>sexsend/rec</code>, and
<code>grsize</code> (group size)</li>
<li>Model 4: In order to examine sex matching effects, add an
interaction of the sex variables to the model <code>sexsend:sexrec</code>.</li>
<li>Compare models with AIC (see the note about <a href="issues.html#model-comparison">model comparison</a>), e.g. <code>AIC(model1)</code>. A lower value would indicate the
model is preferred.</li>
</ul>
</div>
<div id="patents" class="section level3">
<h3>Patents</h3>
<p>Do a Poisson mixed effect model using the <a href="appendix.html#data">patent data</a>. Model the
number of citations (<code>ncit</code>) based on whether there was opposition
(<code>opposition</code>) and if it was for the biotechnology/pharmaceutical
industry (<code>biopharm</code>). Use year as a random effect to account for
unspecified economic conditions.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="extensions.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;data/patents.RData&#39;</span>)</span></code></pre></div>
<p>Interestingly, one can model overdispersion in a Poisson model by
specifying an random intercept for each observation (<code>subject</code> in the
data). In other words, no specific clustering or grouped structure is
necessary, but we can use the random effect approach to get at the extra
variance.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>I don’t show the formal model here as we did before,
but this is why depicting mixed models solely as ‘multilevel’
becomes a bit problematic in my opinion. In the standard mixed model
notation it’s straightforward though, you just add an additional
random effect term, just as we do in the actual model syntax.<a href="extensions.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Setting aside our discussion to take a turn regarding
regression modeling more generally, this is a good example of
‘surprising’ effects not being so surprising when you consider them
more closely. Take a look at the effect of experience. More
experience means less stress, this is probably not surprising. Now
look at the age effect. It’s positive! But wouldn’t older nurses
have more experience? What’s going on here? When interpreting
experience, it is with age <em>held constant</em>, thus more experience
helps with lowering stress no matter what your age. With age, we’re
holding experience constant. If experience doesn’t matter, being
older is affiliated with more stress, which might be expected given
the type of very busy and high pressure work often being done (the
mean age is 43). A good way to better understand
this specifically is to look at predicted values when age is young,
middle, and older vs. experience levels at low, middle, and high
experience, possibly explicitly including the interaction of the two
in the model. Also note that if you take experience out of the
model, the age effect is negative, which is expected, as it captures
experience also.<a href="extensions.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Just a reminder, it <em>does</em> matter if you label your
data in a less than optimal fashion. For example, if in the nesting
situation you start your id variable at 1 for each nested group,
then you have to use the nested notation in <span class="pack">lme4</span>,
otherwise, e.g. it won’t know that id = 1 in group 1 is different
from id 1 in group 2. In our hospital example, this would be akin to
using <code>ward</code> instead of <code>wardid</code> as we did. Again though, this
wouldn’t be an issue if one practices good data habits. Note also
the <code>:</code> syntax. In other modeling contexts in R this denotes an
interaction, and that is no different here. In some contexts,
typically due to experimental designs, one would want to explore
random effects of the sort 1|A, 1|B and 1|A:B. However, this is
relatively rare.<a href="extensions.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>One reason to do so would be that you expect
variability to decrease over time, e.g. due to experience. You might
also allow that variance to be different due to some other grouping
factor entirely (e.g. due to treatment group membership).<a href="extensions.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>This feature request has been made by its users for
over a decade at this point- it’s not gonna happen. The issue is
that the way <span class="pack">lmer</span> works by default employs a method that
won’t allow it (this is why it is faster and better performing than
other packages). Unfortunately the common response to this issue is
‘use <span class="pack">nlme</span>.’ However many other packages work with
<span class="pack">lme4</span> rather than <span class="pack">nlme</span>, and if you aren’t going to
use <span class="pack">lme4</span> for mixed models you might as well go Bayesian
with <span class="pack">rstanarm</span> or <span class="pack">brms</span> instead of <span class="pack">nlme</span>. I
would even prefer <span class="pack">mgcv</span> to <span class="pack">nlme</span> (though it can use
<span class="pack">nlme</span> under the hood) because of the other capabilities it
provides, and the objects created are easier to work with in my
opinion.<a href="extensions.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Note that for a balanced binary variable, the mean
<code>p=.5</code> and standard deviation is <code>sqrt(p*(1-p)) = .5</code><a href="extensions.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random_slopes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="issues.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["twitter", "facebook", "linkedin", "google", "weibo", "instapaper"],
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/m-clark/mixed-models-with-R/blob/master/extensions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"depth": 2,
"scroll_highlight": true
},
"df_print": "kable",
"highlight": "pygments",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
